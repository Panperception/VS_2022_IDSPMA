{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0Q65TgHBh7K"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNrX0PyvBkug",
        "outputId": "62e44d55-ae97-42ec-f23d-f6969605a554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt3DdppZBnS6"
      },
      "outputs": [],
      "source": [
        "path1 = \"/content/drive/MyDrive/Data /FinalMerge.csv\"\n",
        "data = pd.read_csv(path1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "zx1OSDmzCAF6",
        "outputId": "9ad370a6-ada4-40b1-8511-9a255a3cb908"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-681e8eb2-5356-4b2b-bc52-483ef7fa6e69\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>CellLine</th>\n",
              "      <th>Drug_ID</th>\n",
              "      <th>IC50</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>...</th>\n",
              "      <th>216.1</th>\n",
              "      <th>217.1</th>\n",
              "      <th>218.1</th>\n",
              "      <th>219.1</th>\n",
              "      <th>220.1</th>\n",
              "      <th>221.1</th>\n",
              "      <th>222.1</th>\n",
              "      <th>223.1</th>\n",
              "      <th>224.1</th>\n",
              "      <th>225.1</th>\n",
              "      <th>226.1</th>\n",
              "      <th>227.1</th>\n",
              "      <th>228.1</th>\n",
              "      <th>229.1</th>\n",
              "      <th>230.1</th>\n",
              "      <th>231.1</th>\n",
              "      <th>232.1</th>\n",
              "      <th>233.1</th>\n",
              "      <th>234.1</th>\n",
              "      <th>235.1</th>\n",
              "      <th>236.1</th>\n",
              "      <th>237.1</th>\n",
              "      <th>238.1</th>\n",
              "      <th>239.1</th>\n",
              "      <th>240.1</th>\n",
              "      <th>241.1</th>\n",
              "      <th>242.1</th>\n",
              "      <th>243.1</th>\n",
              "      <th>244.1</th>\n",
              "      <th>245.1</th>\n",
              "      <th>246.1</th>\n",
              "      <th>247.1</th>\n",
              "      <th>248.1</th>\n",
              "      <th>249.1</th>\n",
              "      <th>250.1</th>\n",
              "      <th>251.1</th>\n",
              "      <th>252.1</th>\n",
              "      <th>253.1</th>\n",
              "      <th>254.1</th>\n",
              "      <th>255.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ACH-000001</td>\n",
              "      <td>BRD-A00077618-236-07-6</td>\n",
              "      <td>-0.015577</td>\n",
              "      <td>-1.728556</td>\n",
              "      <td>2.433999</td>\n",
              "      <td>-1.019930</td>\n",
              "      <td>-1.757898</td>\n",
              "      <td>0.581074</td>\n",
              "      <td>-1.755267</td>\n",
              "      <td>4.228473</td>\n",
              "      <td>11.930831</td>\n",
              "      <td>1.277193</td>\n",
              "      <td>6.407866</td>\n",
              "      <td>10.054983</td>\n",
              "      <td>3.686244</td>\n",
              "      <td>-1.478580</td>\n",
              "      <td>-1.756955</td>\n",
              "      <td>5.688684</td>\n",
              "      <td>5.094495</td>\n",
              "      <td>5.159706</td>\n",
              "      <td>13.130322</td>\n",
              "      <td>-1.753273</td>\n",
              "      <td>6.061655</td>\n",
              "      <td>-1.458180</td>\n",
              "      <td>-0.655714</td>\n",
              "      <td>-0.800840</td>\n",
              "      <td>4.223152</td>\n",
              "      <td>3.307067</td>\n",
              "      <td>-1.758053</td>\n",
              "      <td>-1.734444</td>\n",
              "      <td>1.684067</td>\n",
              "      <td>1.012239</td>\n",
              "      <td>-1.723961</td>\n",
              "      <td>2.282735</td>\n",
              "      <td>-1.688657</td>\n",
              "      <td>1.826957</td>\n",
              "      <td>4.558780</td>\n",
              "      <td>-1.754363</td>\n",
              "      <td>-1.756690</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ACH-000007</td>\n",
              "      <td>BRD-A00077618-236-07-6</td>\n",
              "      <td>-0.095730</td>\n",
              "      <td>-1.616083</td>\n",
              "      <td>-0.771061</td>\n",
              "      <td>0.756457</td>\n",
              "      <td>-1.753133</td>\n",
              "      <td>1.491488</td>\n",
              "      <td>-1.756090</td>\n",
              "      <td>3.300556</td>\n",
              "      <td>19.351883</td>\n",
              "      <td>-1.369320</td>\n",
              "      <td>1.282292</td>\n",
              "      <td>2.253259</td>\n",
              "      <td>3.900788</td>\n",
              "      <td>-1.636076</td>\n",
              "      <td>-1.758013</td>\n",
              "      <td>-1.414857</td>\n",
              "      <td>6.376349</td>\n",
              "      <td>6.380097</td>\n",
              "      <td>12.358499</td>\n",
              "      <td>-1.740736</td>\n",
              "      <td>5.522613</td>\n",
              "      <td>1.900356</td>\n",
              "      <td>-1.321983</td>\n",
              "      <td>-1.008918</td>\n",
              "      <td>8.447057</td>\n",
              "      <td>7.572113</td>\n",
              "      <td>-1.757873</td>\n",
              "      <td>-1.703370</td>\n",
              "      <td>5.175867</td>\n",
              "      <td>6.213225</td>\n",
              "      <td>-1.683146</td>\n",
              "      <td>3.545616</td>\n",
              "      <td>-1.752450</td>\n",
              "      <td>3.046654</td>\n",
              "      <td>5.377875</td>\n",
              "      <td>-1.726717</td>\n",
              "      <td>-1.743359</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ACH-000008</td>\n",
              "      <td>BRD-A00077618-236-07-6</td>\n",
              "      <td>0.379480</td>\n",
              "      <td>-1.230021</td>\n",
              "      <td>5.240048</td>\n",
              "      <td>1.379720</td>\n",
              "      <td>-1.757688</td>\n",
              "      <td>1.186564</td>\n",
              "      <td>-1.757788</td>\n",
              "      <td>6.258858</td>\n",
              "      <td>9.067563</td>\n",
              "      <td>-0.680781</td>\n",
              "      <td>4.748775</td>\n",
              "      <td>9.537188</td>\n",
              "      <td>9.402541</td>\n",
              "      <td>-0.968205</td>\n",
              "      <td>-1.754238</td>\n",
              "      <td>9.814918</td>\n",
              "      <td>6.873575</td>\n",
              "      <td>8.750247</td>\n",
              "      <td>18.125177</td>\n",
              "      <td>-1.757897</td>\n",
              "      <td>4.825569</td>\n",
              "      <td>-0.825798</td>\n",
              "      <td>0.169827</td>\n",
              "      <td>4.689946</td>\n",
              "      <td>0.951656</td>\n",
              "      <td>1.068404</td>\n",
              "      <td>-1.758077</td>\n",
              "      <td>-1.736978</td>\n",
              "      <td>3.728566</td>\n",
              "      <td>8.849792</td>\n",
              "      <td>-1.756784</td>\n",
              "      <td>0.143789</td>\n",
              "      <td>-1.704643</td>\n",
              "      <td>2.109847</td>\n",
              "      <td>4.786537</td>\n",
              "      <td>-1.746333</td>\n",
              "      <td>-1.757513</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ACH-000010</td>\n",
              "      <td>BRD-A00077618-236-07-6</td>\n",
              "      <td>0.118890</td>\n",
              "      <td>-1.713630</td>\n",
              "      <td>4.790173</td>\n",
              "      <td>-0.075236</td>\n",
              "      <td>-1.757076</td>\n",
              "      <td>-0.659162</td>\n",
              "      <td>-1.756251</td>\n",
              "      <td>5.472468</td>\n",
              "      <td>13.853428</td>\n",
              "      <td>1.338245</td>\n",
              "      <td>8.216239</td>\n",
              "      <td>9.874049</td>\n",
              "      <td>5.183456</td>\n",
              "      <td>-1.560059</td>\n",
              "      <td>-1.752247</td>\n",
              "      <td>8.714049</td>\n",
              "      <td>7.576016</td>\n",
              "      <td>7.060184</td>\n",
              "      <td>13.696853</td>\n",
              "      <td>-1.756716</td>\n",
              "      <td>8.130669</td>\n",
              "      <td>-1.564248</td>\n",
              "      <td>-0.827464</td>\n",
              "      <td>3.788671</td>\n",
              "      <td>0.889381</td>\n",
              "      <td>0.356038</td>\n",
              "      <td>-1.758017</td>\n",
              "      <td>-1.707353</td>\n",
              "      <td>1.883788</td>\n",
              "      <td>3.547088</td>\n",
              "      <td>-1.741584</td>\n",
              "      <td>2.407140</td>\n",
              "      <td>-1.745215</td>\n",
              "      <td>-0.464359</td>\n",
              "      <td>7.394870</td>\n",
              "      <td>-1.747943</td>\n",
              "      <td>-1.753574</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ACH-000011</td>\n",
              "      <td>BRD-A00077618-236-07-6</td>\n",
              "      <td>0.145346</td>\n",
              "      <td>-1.720528</td>\n",
              "      <td>1.592634</td>\n",
              "      <td>1.981018</td>\n",
              "      <td>-1.757607</td>\n",
              "      <td>0.630482</td>\n",
              "      <td>-1.753977</td>\n",
              "      <td>4.662811</td>\n",
              "      <td>12.751846</td>\n",
              "      <td>1.074993</td>\n",
              "      <td>5.462288</td>\n",
              "      <td>6.408267</td>\n",
              "      <td>6.239316</td>\n",
              "      <td>-1.548074</td>\n",
              "      <td>-1.755546</td>\n",
              "      <td>5.446209</td>\n",
              "      <td>6.882668</td>\n",
              "      <td>6.231433</td>\n",
              "      <td>15.046421</td>\n",
              "      <td>-1.757021</td>\n",
              "      <td>6.341629</td>\n",
              "      <td>1.087580</td>\n",
              "      <td>-0.344353</td>\n",
              "      <td>-0.536584</td>\n",
              "      <td>4.180730</td>\n",
              "      <td>1.469086</td>\n",
              "      <td>-1.758014</td>\n",
              "      <td>-1.686345</td>\n",
              "      <td>2.930312</td>\n",
              "      <td>3.779099</td>\n",
              "      <td>-1.738527</td>\n",
              "      <td>4.007609</td>\n",
              "      <td>-1.743249</td>\n",
              "      <td>0.342900</td>\n",
              "      <td>5.377270</td>\n",
              "      <td>-1.750576</td>\n",
              "      <td>-1.756797</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19834</th>\n",
              "      <td>19834</td>\n",
              "      <td>ACH-001239</td>\n",
              "      <td>BRD-A04322457-003-17-9</td>\n",
              "      <td>0.369926</td>\n",
              "      <td>-1.389295</td>\n",
              "      <td>6.018878</td>\n",
              "      <td>2.696053</td>\n",
              "      <td>-1.757883</td>\n",
              "      <td>0.879858</td>\n",
              "      <td>-1.757979</td>\n",
              "      <td>6.266390</td>\n",
              "      <td>8.563468</td>\n",
              "      <td>-1.328204</td>\n",
              "      <td>5.375595</td>\n",
              "      <td>9.389275</td>\n",
              "      <td>8.908756</td>\n",
              "      <td>-0.825840</td>\n",
              "      <td>-1.749972</td>\n",
              "      <td>10.664358</td>\n",
              "      <td>7.641659</td>\n",
              "      <td>9.567306</td>\n",
              "      <td>16.609623</td>\n",
              "      <td>-1.757955</td>\n",
              "      <td>6.229425</td>\n",
              "      <td>-0.871218</td>\n",
              "      <td>-0.219832</td>\n",
              "      <td>6.038338</td>\n",
              "      <td>2.092164</td>\n",
              "      <td>0.528440</td>\n",
              "      <td>-1.758079</td>\n",
              "      <td>-1.727836</td>\n",
              "      <td>4.124252</td>\n",
              "      <td>7.758388</td>\n",
              "      <td>-1.756457</td>\n",
              "      <td>-1.023202</td>\n",
              "      <td>-1.681456</td>\n",
              "      <td>2.456260</td>\n",
              "      <td>5.961589</td>\n",
              "      <td>-1.753670</td>\n",
              "      <td>-1.756886</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19835</th>\n",
              "      <td>19835</td>\n",
              "      <td>ACH-001306</td>\n",
              "      <td>BRD-A04322457-003-17-9</td>\n",
              "      <td>-0.039914</td>\n",
              "      <td>-1.721469</td>\n",
              "      <td>6.470818</td>\n",
              "      <td>0.637218</td>\n",
              "      <td>-1.757760</td>\n",
              "      <td>0.096986</td>\n",
              "      <td>-1.756002</td>\n",
              "      <td>4.812477</td>\n",
              "      <td>9.989901</td>\n",
              "      <td>3.417594</td>\n",
              "      <td>6.272072</td>\n",
              "      <td>10.238437</td>\n",
              "      <td>8.883233</td>\n",
              "      <td>-1.154211</td>\n",
              "      <td>-1.753805</td>\n",
              "      <td>7.669941</td>\n",
              "      <td>8.147975</td>\n",
              "      <td>8.462427</td>\n",
              "      <td>17.399153</td>\n",
              "      <td>-1.757613</td>\n",
              "      <td>4.024602</td>\n",
              "      <td>-0.487762</td>\n",
              "      <td>2.858115</td>\n",
              "      <td>1.388427</td>\n",
              "      <td>1.917493</td>\n",
              "      <td>1.516732</td>\n",
              "      <td>-1.758068</td>\n",
              "      <td>-1.754246</td>\n",
              "      <td>1.485408</td>\n",
              "      <td>5.743079</td>\n",
              "      <td>-1.753075</td>\n",
              "      <td>0.384726</td>\n",
              "      <td>-1.744678</td>\n",
              "      <td>2.402699</td>\n",
              "      <td>5.569891</td>\n",
              "      <td>-1.724864</td>\n",
              "      <td>-1.757925</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19836</th>\n",
              "      <td>19836</td>\n",
              "      <td>ACH-001307</td>\n",
              "      <td>BRD-A04322457-003-17-9</td>\n",
              "      <td>0.404810</td>\n",
              "      <td>-1.710602</td>\n",
              "      <td>5.898825</td>\n",
              "      <td>-0.311783</td>\n",
              "      <td>-1.757319</td>\n",
              "      <td>-0.310616</td>\n",
              "      <td>-1.755317</td>\n",
              "      <td>5.774302</td>\n",
              "      <td>12.299385</td>\n",
              "      <td>2.446027</td>\n",
              "      <td>5.852395</td>\n",
              "      <td>10.389279</td>\n",
              "      <td>8.543776</td>\n",
              "      <td>-1.397955</td>\n",
              "      <td>-1.756517</td>\n",
              "      <td>6.998185</td>\n",
              "      <td>8.700681</td>\n",
              "      <td>8.511920</td>\n",
              "      <td>18.551580</td>\n",
              "      <td>-1.756882</td>\n",
              "      <td>4.248174</td>\n",
              "      <td>-0.928221</td>\n",
              "      <td>2.321364</td>\n",
              "      <td>1.372049</td>\n",
              "      <td>2.907662</td>\n",
              "      <td>2.339866</td>\n",
              "      <td>-1.758064</td>\n",
              "      <td>-1.755299</td>\n",
              "      <td>1.123555</td>\n",
              "      <td>7.331820</td>\n",
              "      <td>-1.754491</td>\n",
              "      <td>-0.046743</td>\n",
              "      <td>-1.747261</td>\n",
              "      <td>2.219655</td>\n",
              "      <td>5.189868</td>\n",
              "      <td>-1.685083</td>\n",
              "      <td>-1.757923</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19837</th>\n",
              "      <td>19837</td>\n",
              "      <td>ACH-001318</td>\n",
              "      <td>BRD-A04322457-003-17-9</td>\n",
              "      <td>0.074413</td>\n",
              "      <td>-1.717019</td>\n",
              "      <td>1.310033</td>\n",
              "      <td>-0.661595</td>\n",
              "      <td>-1.757362</td>\n",
              "      <td>0.470754</td>\n",
              "      <td>-1.755819</td>\n",
              "      <td>4.396008</td>\n",
              "      <td>14.152803</td>\n",
              "      <td>-0.288965</td>\n",
              "      <td>4.483595</td>\n",
              "      <td>8.577558</td>\n",
              "      <td>6.064391</td>\n",
              "      <td>-1.616083</td>\n",
              "      <td>-1.756497</td>\n",
              "      <td>5.888326</td>\n",
              "      <td>6.223103</td>\n",
              "      <td>6.114912</td>\n",
              "      <td>14.093079</td>\n",
              "      <td>-1.756877</td>\n",
              "      <td>6.322864</td>\n",
              "      <td>-0.571596</td>\n",
              "      <td>-0.905433</td>\n",
              "      <td>0.514613</td>\n",
              "      <td>3.349801</td>\n",
              "      <td>2.652906</td>\n",
              "      <td>-1.758039</td>\n",
              "      <td>-1.699571</td>\n",
              "      <td>3.191881</td>\n",
              "      <td>4.133726</td>\n",
              "      <td>-1.741737</td>\n",
              "      <td>3.745676</td>\n",
              "      <td>-1.744436</td>\n",
              "      <td>0.787618</td>\n",
              "      <td>6.022370</td>\n",
              "      <td>-1.749683</td>\n",
              "      <td>-1.756604</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19838</th>\n",
              "      <td>19838</td>\n",
              "      <td>ACH-001321</td>\n",
              "      <td>BRD-A04322457-003-17-9</td>\n",
              "      <td>0.186287</td>\n",
              "      <td>-1.697286</td>\n",
              "      <td>0.126924</td>\n",
              "      <td>0.420004</td>\n",
              "      <td>-1.757983</td>\n",
              "      <td>2.383193</td>\n",
              "      <td>-1.757616</td>\n",
              "      <td>2.272727</td>\n",
              "      <td>10.218188</td>\n",
              "      <td>1.211467</td>\n",
              "      <td>6.210011</td>\n",
              "      <td>12.504049</td>\n",
              "      <td>0.914692</td>\n",
              "      <td>-0.296067</td>\n",
              "      <td>-1.754630</td>\n",
              "      <td>5.477245</td>\n",
              "      <td>2.444343</td>\n",
              "      <td>3.600807</td>\n",
              "      <td>5.974332</td>\n",
              "      <td>-1.757282</td>\n",
              "      <td>6.936205</td>\n",
              "      <td>-1.715856</td>\n",
              "      <td>-1.609016</td>\n",
              "      <td>0.356200</td>\n",
              "      <td>-0.771862</td>\n",
              "      <td>5.140345</td>\n",
              "      <td>-1.757999</td>\n",
              "      <td>-1.146301</td>\n",
              "      <td>3.891873</td>\n",
              "      <td>-1.667401</td>\n",
              "      <td>-1.412931</td>\n",
              "      <td>0.806523</td>\n",
              "      <td>-1.665718</td>\n",
              "      <td>1.600254</td>\n",
              "      <td>7.922114</td>\n",
              "      <td>-1.757304</td>\n",
              "      <td>-1.691766</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19839 rows Ã— 760 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-681e8eb2-5356-4b2b-bc52-483ef7fa6e69')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-681e8eb2-5356-4b2b-bc52-483ef7fa6e69 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-681e8eb2-5356-4b2b-bc52-483ef7fa6e69');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0    CellLine                 Drug_ID  ...  253.1  254.1  255.1\n",
              "0               0  ACH-000001  BRD-A00077618-236-07-6  ...      0      0      1\n",
              "1               1  ACH-000007  BRD-A00077618-236-07-6  ...      0      0      1\n",
              "2               2  ACH-000008  BRD-A00077618-236-07-6  ...      0      0      1\n",
              "3               3  ACH-000010  BRD-A00077618-236-07-6  ...      0      0      1\n",
              "4               4  ACH-000011  BRD-A00077618-236-07-6  ...      0      0      1\n",
              "...           ...         ...                     ...  ...    ...    ...    ...\n",
              "19834       19834  ACH-001239  BRD-A04322457-003-17-9  ...      0      0      0\n",
              "19835       19835  ACH-001306  BRD-A04322457-003-17-9  ...      0      0      0\n",
              "19836       19836  ACH-001307  BRD-A04322457-003-17-9  ...      0      0      0\n",
              "19837       19837  ACH-001318  BRD-A04322457-003-17-9  ...      0      0      0\n",
              "19838       19838  ACH-001321  BRD-A04322457-003-17-9  ...      0      0      0\n",
              "\n",
              "[19839 rows x 760 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dXXRQAotiMU"
      },
      "outputs": [],
      "source": [
        "d=data.drop(['Unnamed: 0'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "zSzxJI7VttEi",
        "outputId": "8cdbe020-1443-4815-dc1a-93b18b894424"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3751846b-7c38-4d74-b4d9-b98a7f3b7e5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CellLine</th>\n",
              "      <th>Drug_ID</th>\n",
              "      <th>IC50</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>...</th>\n",
              "      <th>216.1</th>\n",
              "      <th>217.1</th>\n",
              "      <th>218.1</th>\n",
              "      <th>219.1</th>\n",
              "      <th>220.1</th>\n",
              "      <th>221.1</th>\n",
              "      <th>222.1</th>\n",
              "      <th>223.1</th>\n",
              "      <th>224.1</th>\n",
              "      <th>225.1</th>\n",
              "      <th>226.1</th>\n",
              "      <th>227.1</th>\n",
              "      <th>228.1</th>\n",
              "      <th>229.1</th>\n",
              "      <th>230.1</th>\n",
              "      <th>231.1</th>\n",
              "      <th>232.1</th>\n",
              "      <th>233.1</th>\n",
              "      <th>234.1</th>\n",
              "      <th>235.1</th>\n",
              "      <th>236.1</th>\n",
              "      <th>237.1</th>\n",
              "      <th>238.1</th>\n",
              "      <th>239.1</th>\n",
              "      <th>240.1</th>\n",
              "      <th>241.1</th>\n",
              "      <th>242.1</th>\n",
              "      <th>243.1</th>\n",
              "      <th>244.1</th>\n",
              "      <th>245.1</th>\n",
              "      <th>246.1</th>\n",
              "      <th>247.1</th>\n",
              "      <th>248.1</th>\n",
              "      <th>249.1</th>\n",
              "      <th>250.1</th>\n",
              "      <th>251.1</th>\n",
              "      <th>252.1</th>\n",
              "      <th>253.1</th>\n",
              "      <th>254.1</th>\n",
              "      <th>255.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ACH-000001</td>\n",
              "      <td>BRD-A00077618-236-07-6</td>\n",
              "      <td>-0.015577</td>\n",
              "      <td>-1.728556</td>\n",
              "      <td>2.433999</td>\n",
              "      <td>-1.019930</td>\n",
              "      <td>-1.757898</td>\n",
              "      <td>0.581074</td>\n",
              "      <td>-1.755267</td>\n",
              "      <td>4.228473</td>\n",
              "      <td>11.930831</td>\n",
              "      <td>1.277193</td>\n",
              "      <td>6.407866</td>\n",
              "      <td>10.054983</td>\n",
              "      <td>3.686244</td>\n",
              "      <td>-1.478580</td>\n",
              "      <td>-1.756955</td>\n",
              "      <td>5.688684</td>\n",
              "      <td>5.094495</td>\n",
              "      <td>5.159706</td>\n",
              "      <td>13.130322</td>\n",
              "      <td>-1.753273</td>\n",
              "      <td>6.061655</td>\n",
              "      <td>-1.458180</td>\n",
              "      <td>-0.655714</td>\n",
              "      <td>-0.800840</td>\n",
              "      <td>4.223152</td>\n",
              "      <td>3.307067</td>\n",
              "      <td>-1.758053</td>\n",
              "      <td>-1.734444</td>\n",
              "      <td>1.684067</td>\n",
              "      <td>1.012239</td>\n",
              "      <td>-1.723961</td>\n",
              "      <td>2.282735</td>\n",
              "      <td>-1.688657</td>\n",
              "      <td>1.826957</td>\n",
              "      <td>4.558780</td>\n",
              "      <td>-1.754363</td>\n",
              "      <td>-1.756690</td>\n",
              "      <td>-1.753150</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ACH-000007</td>\n",
              "      <td>BRD-A00077618-236-07-6</td>\n",
              "      <td>-0.095730</td>\n",
              "      <td>-1.616083</td>\n",
              "      <td>-0.771061</td>\n",
              "      <td>0.756457</td>\n",
              "      <td>-1.753133</td>\n",
              "      <td>1.491488</td>\n",
              "      <td>-1.756090</td>\n",
              "      <td>3.300556</td>\n",
              "      <td>19.351883</td>\n",
              "      <td>-1.369320</td>\n",
              "      <td>1.282292</td>\n",
              "      <td>2.253259</td>\n",
              "      <td>3.900788</td>\n",
              "      <td>-1.636076</td>\n",
              "      <td>-1.758013</td>\n",
              "      <td>-1.414857</td>\n",
              "      <td>6.376349</td>\n",
              "      <td>6.380097</td>\n",
              "      <td>12.358499</td>\n",
              "      <td>-1.740736</td>\n",
              "      <td>5.522613</td>\n",
              "      <td>1.900356</td>\n",
              "      <td>-1.321983</td>\n",
              "      <td>-1.008918</td>\n",
              "      <td>8.447057</td>\n",
              "      <td>7.572113</td>\n",
              "      <td>-1.757873</td>\n",
              "      <td>-1.703370</td>\n",
              "      <td>5.175867</td>\n",
              "      <td>6.213225</td>\n",
              "      <td>-1.683146</td>\n",
              "      <td>3.545616</td>\n",
              "      <td>-1.752450</td>\n",
              "      <td>3.046654</td>\n",
              "      <td>5.377875</td>\n",
              "      <td>-1.726717</td>\n",
              "      <td>-1.743359</td>\n",
              "      <td>-1.749476</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ACH-000008</td>\n",
              "      <td>BRD-A00077618-236-07-6</td>\n",
              "      <td>0.379480</td>\n",
              "      <td>-1.230021</td>\n",
              "      <td>5.240048</td>\n",
              "      <td>1.379720</td>\n",
              "      <td>-1.757688</td>\n",
              "      <td>1.186564</td>\n",
              "      <td>-1.757788</td>\n",
              "      <td>6.258858</td>\n",
              "      <td>9.067563</td>\n",
              "      <td>-0.680781</td>\n",
              "      <td>4.748775</td>\n",
              "      <td>9.537188</td>\n",
              "      <td>9.402541</td>\n",
              "      <td>-0.968205</td>\n",
              "      <td>-1.754238</td>\n",
              "      <td>9.814918</td>\n",
              "      <td>6.873575</td>\n",
              "      <td>8.750247</td>\n",
              "      <td>18.125177</td>\n",
              "      <td>-1.757897</td>\n",
              "      <td>4.825569</td>\n",
              "      <td>-0.825798</td>\n",
              "      <td>0.169827</td>\n",
              "      <td>4.689946</td>\n",
              "      <td>0.951656</td>\n",
              "      <td>1.068404</td>\n",
              "      <td>-1.758077</td>\n",
              "      <td>-1.736978</td>\n",
              "      <td>3.728566</td>\n",
              "      <td>8.849792</td>\n",
              "      <td>-1.756784</td>\n",
              "      <td>0.143789</td>\n",
              "      <td>-1.704643</td>\n",
              "      <td>2.109847</td>\n",
              "      <td>4.786537</td>\n",
              "      <td>-1.746333</td>\n",
              "      <td>-1.757513</td>\n",
              "      <td>-1.743727</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ACH-000010</td>\n",
              "      <td>BRD-A00077618-236-07-6</td>\n",
              "      <td>0.118890</td>\n",
              "      <td>-1.713630</td>\n",
              "      <td>4.790173</td>\n",
              "      <td>-0.075236</td>\n",
              "      <td>-1.757076</td>\n",
              "      <td>-0.659162</td>\n",
              "      <td>-1.756251</td>\n",
              "      <td>5.472468</td>\n",
              "      <td>13.853428</td>\n",
              "      <td>1.338245</td>\n",
              "      <td>8.216239</td>\n",
              "      <td>9.874049</td>\n",
              "      <td>5.183456</td>\n",
              "      <td>-1.560059</td>\n",
              "      <td>-1.752247</td>\n",
              "      <td>8.714049</td>\n",
              "      <td>7.576016</td>\n",
              "      <td>7.060184</td>\n",
              "      <td>13.696853</td>\n",
              "      <td>-1.756716</td>\n",
              "      <td>8.130669</td>\n",
              "      <td>-1.564248</td>\n",
              "      <td>-0.827464</td>\n",
              "      <td>3.788671</td>\n",
              "      <td>0.889381</td>\n",
              "      <td>0.356038</td>\n",
              "      <td>-1.758017</td>\n",
              "      <td>-1.707353</td>\n",
              "      <td>1.883788</td>\n",
              "      <td>3.547088</td>\n",
              "      <td>-1.741584</td>\n",
              "      <td>2.407140</td>\n",
              "      <td>-1.745215</td>\n",
              "      <td>-0.464359</td>\n",
              "      <td>7.394870</td>\n",
              "      <td>-1.747943</td>\n",
              "      <td>-1.753574</td>\n",
              "      <td>-1.728868</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACH-000011</td>\n",
              "      <td>BRD-A00077618-236-07-6</td>\n",
              "      <td>0.145346</td>\n",
              "      <td>-1.720528</td>\n",
              "      <td>1.592634</td>\n",
              "      <td>1.981018</td>\n",
              "      <td>-1.757607</td>\n",
              "      <td>0.630482</td>\n",
              "      <td>-1.753977</td>\n",
              "      <td>4.662811</td>\n",
              "      <td>12.751846</td>\n",
              "      <td>1.074993</td>\n",
              "      <td>5.462288</td>\n",
              "      <td>6.408267</td>\n",
              "      <td>6.239316</td>\n",
              "      <td>-1.548074</td>\n",
              "      <td>-1.755546</td>\n",
              "      <td>5.446209</td>\n",
              "      <td>6.882668</td>\n",
              "      <td>6.231433</td>\n",
              "      <td>15.046421</td>\n",
              "      <td>-1.757021</td>\n",
              "      <td>6.341629</td>\n",
              "      <td>1.087580</td>\n",
              "      <td>-0.344353</td>\n",
              "      <td>-0.536584</td>\n",
              "      <td>4.180730</td>\n",
              "      <td>1.469086</td>\n",
              "      <td>-1.758014</td>\n",
              "      <td>-1.686345</td>\n",
              "      <td>2.930312</td>\n",
              "      <td>3.779099</td>\n",
              "      <td>-1.738527</td>\n",
              "      <td>4.007609</td>\n",
              "      <td>-1.743249</td>\n",
              "      <td>0.342900</td>\n",
              "      <td>5.377270</td>\n",
              "      <td>-1.750576</td>\n",
              "      <td>-1.756797</td>\n",
              "      <td>-1.753634</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19834</th>\n",
              "      <td>ACH-001239</td>\n",
              "      <td>BRD-A04322457-003-17-9</td>\n",
              "      <td>0.369926</td>\n",
              "      <td>-1.389295</td>\n",
              "      <td>6.018878</td>\n",
              "      <td>2.696053</td>\n",
              "      <td>-1.757883</td>\n",
              "      <td>0.879858</td>\n",
              "      <td>-1.757979</td>\n",
              "      <td>6.266390</td>\n",
              "      <td>8.563468</td>\n",
              "      <td>-1.328204</td>\n",
              "      <td>5.375595</td>\n",
              "      <td>9.389275</td>\n",
              "      <td>8.908756</td>\n",
              "      <td>-0.825840</td>\n",
              "      <td>-1.749972</td>\n",
              "      <td>10.664358</td>\n",
              "      <td>7.641659</td>\n",
              "      <td>9.567306</td>\n",
              "      <td>16.609623</td>\n",
              "      <td>-1.757955</td>\n",
              "      <td>6.229425</td>\n",
              "      <td>-0.871218</td>\n",
              "      <td>-0.219832</td>\n",
              "      <td>6.038338</td>\n",
              "      <td>2.092164</td>\n",
              "      <td>0.528440</td>\n",
              "      <td>-1.758079</td>\n",
              "      <td>-1.727836</td>\n",
              "      <td>4.124252</td>\n",
              "      <td>7.758388</td>\n",
              "      <td>-1.756457</td>\n",
              "      <td>-1.023202</td>\n",
              "      <td>-1.681456</td>\n",
              "      <td>2.456260</td>\n",
              "      <td>5.961589</td>\n",
              "      <td>-1.753670</td>\n",
              "      <td>-1.756886</td>\n",
              "      <td>-1.732060</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19835</th>\n",
              "      <td>ACH-001306</td>\n",
              "      <td>BRD-A04322457-003-17-9</td>\n",
              "      <td>-0.039914</td>\n",
              "      <td>-1.721469</td>\n",
              "      <td>6.470818</td>\n",
              "      <td>0.637218</td>\n",
              "      <td>-1.757760</td>\n",
              "      <td>0.096986</td>\n",
              "      <td>-1.756002</td>\n",
              "      <td>4.812477</td>\n",
              "      <td>9.989901</td>\n",
              "      <td>3.417594</td>\n",
              "      <td>6.272072</td>\n",
              "      <td>10.238437</td>\n",
              "      <td>8.883233</td>\n",
              "      <td>-1.154211</td>\n",
              "      <td>-1.753805</td>\n",
              "      <td>7.669941</td>\n",
              "      <td>8.147975</td>\n",
              "      <td>8.462427</td>\n",
              "      <td>17.399153</td>\n",
              "      <td>-1.757613</td>\n",
              "      <td>4.024602</td>\n",
              "      <td>-0.487762</td>\n",
              "      <td>2.858115</td>\n",
              "      <td>1.388427</td>\n",
              "      <td>1.917493</td>\n",
              "      <td>1.516732</td>\n",
              "      <td>-1.758068</td>\n",
              "      <td>-1.754246</td>\n",
              "      <td>1.485408</td>\n",
              "      <td>5.743079</td>\n",
              "      <td>-1.753075</td>\n",
              "      <td>0.384726</td>\n",
              "      <td>-1.744678</td>\n",
              "      <td>2.402699</td>\n",
              "      <td>5.569891</td>\n",
              "      <td>-1.724864</td>\n",
              "      <td>-1.757925</td>\n",
              "      <td>-1.752965</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19836</th>\n",
              "      <td>ACH-001307</td>\n",
              "      <td>BRD-A04322457-003-17-9</td>\n",
              "      <td>0.404810</td>\n",
              "      <td>-1.710602</td>\n",
              "      <td>5.898825</td>\n",
              "      <td>-0.311783</td>\n",
              "      <td>-1.757319</td>\n",
              "      <td>-0.310616</td>\n",
              "      <td>-1.755317</td>\n",
              "      <td>5.774302</td>\n",
              "      <td>12.299385</td>\n",
              "      <td>2.446027</td>\n",
              "      <td>5.852395</td>\n",
              "      <td>10.389279</td>\n",
              "      <td>8.543776</td>\n",
              "      <td>-1.397955</td>\n",
              "      <td>-1.756517</td>\n",
              "      <td>6.998185</td>\n",
              "      <td>8.700681</td>\n",
              "      <td>8.511920</td>\n",
              "      <td>18.551580</td>\n",
              "      <td>-1.756882</td>\n",
              "      <td>4.248174</td>\n",
              "      <td>-0.928221</td>\n",
              "      <td>2.321364</td>\n",
              "      <td>1.372049</td>\n",
              "      <td>2.907662</td>\n",
              "      <td>2.339866</td>\n",
              "      <td>-1.758064</td>\n",
              "      <td>-1.755299</td>\n",
              "      <td>1.123555</td>\n",
              "      <td>7.331820</td>\n",
              "      <td>-1.754491</td>\n",
              "      <td>-0.046743</td>\n",
              "      <td>-1.747261</td>\n",
              "      <td>2.219655</td>\n",
              "      <td>5.189868</td>\n",
              "      <td>-1.685083</td>\n",
              "      <td>-1.757923</td>\n",
              "      <td>-1.750471</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19837</th>\n",
              "      <td>ACH-001318</td>\n",
              "      <td>BRD-A04322457-003-17-9</td>\n",
              "      <td>0.074413</td>\n",
              "      <td>-1.717019</td>\n",
              "      <td>1.310033</td>\n",
              "      <td>-0.661595</td>\n",
              "      <td>-1.757362</td>\n",
              "      <td>0.470754</td>\n",
              "      <td>-1.755819</td>\n",
              "      <td>4.396008</td>\n",
              "      <td>14.152803</td>\n",
              "      <td>-0.288965</td>\n",
              "      <td>4.483595</td>\n",
              "      <td>8.577558</td>\n",
              "      <td>6.064391</td>\n",
              "      <td>-1.616083</td>\n",
              "      <td>-1.756497</td>\n",
              "      <td>5.888326</td>\n",
              "      <td>6.223103</td>\n",
              "      <td>6.114912</td>\n",
              "      <td>14.093079</td>\n",
              "      <td>-1.756877</td>\n",
              "      <td>6.322864</td>\n",
              "      <td>-0.571596</td>\n",
              "      <td>-0.905433</td>\n",
              "      <td>0.514613</td>\n",
              "      <td>3.349801</td>\n",
              "      <td>2.652906</td>\n",
              "      <td>-1.758039</td>\n",
              "      <td>-1.699571</td>\n",
              "      <td>3.191881</td>\n",
              "      <td>4.133726</td>\n",
              "      <td>-1.741737</td>\n",
              "      <td>3.745676</td>\n",
              "      <td>-1.744436</td>\n",
              "      <td>0.787618</td>\n",
              "      <td>6.022370</td>\n",
              "      <td>-1.749683</td>\n",
              "      <td>-1.756604</td>\n",
              "      <td>-1.749560</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19838</th>\n",
              "      <td>ACH-001321</td>\n",
              "      <td>BRD-A04322457-003-17-9</td>\n",
              "      <td>0.186287</td>\n",
              "      <td>-1.697286</td>\n",
              "      <td>0.126924</td>\n",
              "      <td>0.420004</td>\n",
              "      <td>-1.757983</td>\n",
              "      <td>2.383193</td>\n",
              "      <td>-1.757616</td>\n",
              "      <td>2.272727</td>\n",
              "      <td>10.218188</td>\n",
              "      <td>1.211467</td>\n",
              "      <td>6.210011</td>\n",
              "      <td>12.504049</td>\n",
              "      <td>0.914692</td>\n",
              "      <td>-0.296067</td>\n",
              "      <td>-1.754630</td>\n",
              "      <td>5.477245</td>\n",
              "      <td>2.444343</td>\n",
              "      <td>3.600807</td>\n",
              "      <td>5.974332</td>\n",
              "      <td>-1.757282</td>\n",
              "      <td>6.936205</td>\n",
              "      <td>-1.715856</td>\n",
              "      <td>-1.609016</td>\n",
              "      <td>0.356200</td>\n",
              "      <td>-0.771862</td>\n",
              "      <td>5.140345</td>\n",
              "      <td>-1.757999</td>\n",
              "      <td>-1.146301</td>\n",
              "      <td>3.891873</td>\n",
              "      <td>-1.667401</td>\n",
              "      <td>-1.412931</td>\n",
              "      <td>0.806523</td>\n",
              "      <td>-1.665718</td>\n",
              "      <td>1.600254</td>\n",
              "      <td>7.922114</td>\n",
              "      <td>-1.757304</td>\n",
              "      <td>-1.691766</td>\n",
              "      <td>-1.744233</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19839 rows Ã— 759 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3751846b-7c38-4d74-b4d9-b98a7f3b7e5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3751846b-7c38-4d74-b4d9-b98a7f3b7e5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3751846b-7c38-4d74-b4d9-b98a7f3b7e5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         CellLine                 Drug_ID      IC50  ...  253.1  254.1  255.1\n",
              "0      ACH-000001  BRD-A00077618-236-07-6 -0.015577  ...      0      0      1\n",
              "1      ACH-000007  BRD-A00077618-236-07-6 -0.095730  ...      0      0      1\n",
              "2      ACH-000008  BRD-A00077618-236-07-6  0.379480  ...      0      0      1\n",
              "3      ACH-000010  BRD-A00077618-236-07-6  0.118890  ...      0      0      1\n",
              "4      ACH-000011  BRD-A00077618-236-07-6  0.145346  ...      0      0      1\n",
              "...           ...                     ...       ...  ...    ...    ...    ...\n",
              "19834  ACH-001239  BRD-A04322457-003-17-9  0.369926  ...      0      0      0\n",
              "19835  ACH-001306  BRD-A04322457-003-17-9 -0.039914  ...      0      0      0\n",
              "19836  ACH-001307  BRD-A04322457-003-17-9  0.404810  ...      0      0      0\n",
              "19837  ACH-001318  BRD-A04322457-003-17-9  0.074413  ...      0      0      0\n",
              "19838  ACH-001321  BRD-A04322457-003-17-9  0.186287  ...      0      0      0\n",
              "\n",
              "[19839 rows x 759 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIoCIvKfxGrz"
      },
      "outputs": [],
      "source": [
        "x=d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krIh4ERZxKaY"
      },
      "outputs": [],
      "source": [
        "x=x.drop(['CellLine','Drug_ID','IC50'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOnMKyZDxRJA",
        "outputId": "266eba5b-6a31-4c07-856b-7126822ed986"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        float64\n",
              "1        float64\n",
              "2        float64\n",
              "3        float64\n",
              "4        float64\n",
              "          ...   \n",
              "251.1      int64\n",
              "252.1      int64\n",
              "253.1      int64\n",
              "254.1      int64\n",
              "255.1      int64\n",
              "Length: 756, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X93colqq7GC6"
      },
      "outputs": [],
      "source": [
        "x2=x.astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG-TdtrY7NIx",
        "outputId": "3cd51f5b-7dec-454c-bdca-21e99c6625d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        float64\n",
              "1        float64\n",
              "2        float64\n",
              "3        float64\n",
              "4        float64\n",
              "          ...   \n",
              "251.1    float64\n",
              "252.1    float64\n",
              "253.1    float64\n",
              "254.1    float64\n",
              "255.1    float64\n",
              "Length: 756, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "x2.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_xhydCLIeYa"
      },
      "outputs": [],
      "source": [
        "v = x2.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ep2Q9vqxxtL",
        "outputId": "39259fb9-f6a8-4261-e198-943d20d5e560"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "d.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkwxQpLcbdTg",
        "outputId": "2a2191b9-fade-4459-f9ed-bfa89aed8cdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "d.isnull().values.any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlHxTdQZyr2f"
      },
      "outputs": [],
      "source": [
        "d2=d.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9okhIrFIx8vC"
      },
      "outputs": [],
      "source": [
        "y = d2[:,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3GWuUdcFzJW",
        "outputId": "fae5e2ca-87ca-45ad-b1a6-965f226a767b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19839,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3YXoN2_2DTt"
      },
      "outputs": [],
      "source": [
        "y2 = np.array(d['IC50'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALzmsW7C7eB3"
      },
      "outputs": [],
      "source": [
        "y = d2[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpv73oJax9c8",
        "outputId": "ceeacec9-d7b7-48f3-95e7-d67b24088dba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19839,)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "y2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exZbyek972dy",
        "outputId": "f29b8bbf-7483-4e2e-bd63-e0c5847ab2fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19839,)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-B4KCtD4gsT",
        "outputId": "93f0e716-050d-44b7-8c5d-7199dd8c66c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "v.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoT0n5GMXEOL"
      },
      "outputs": [],
      "source": [
        "label=d.iloc[:,2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfVgN4DFXVm3",
        "outputId": "05abaffb-9d71-405b-9313-679f961b45fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19839,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze7VBmrBZd2n"
      },
      "outputs": [],
      "source": [
        " v1 = np.asarray(v).astype('float64')\n",
        " y3 = np.asarray(y2).astype('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6MG0YQ6bzgU",
        "outputId": "90ae7653-f970-4ca3-cdde-e485f6d5e9d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19839, 756)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "v1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCyIG1lLWvwu",
        "outputId": "697de931-0c13-4690-b46b-d24d20e9bba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13887, 756) (13887,) (5952, 756) (5952,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(v1, y3, test_size = 0.3, random_state=40)\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7E4jV3kEAnzO"
      },
      "outputs": [],
      "source": [
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YG-2WUe7GjOQ",
        "outputId": "f4c9e946-7f38-4bb4-a05b-3cb60babfef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16664, 756)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(v1, y3, test_size=0.2, random_state=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBcGBtG5UKC-",
        "outputId": "310f8d29-a37f-4e16-dd12-5ccd420541c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12696, 756) (12696,) (3968, 756) (3968,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSZ1or_hvoV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529f6582-0caf-4fdb-c6be-26411d395794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 2.1351 - rmse: 1.4612 - val_loss: 0.4420 - val_rmse: 0.6648\n",
            "Epoch 2/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.4439 - rmse: 0.6662 - val_loss: 0.3266 - val_rmse: 0.5715\n",
            "Epoch 3/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.4138 - rmse: 0.6433 - val_loss: 0.3316 - val_rmse: 0.5758\n",
            "Epoch 4/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.3952 - rmse: 0.6286 - val_loss: 0.3234 - val_rmse: 0.5687\n",
            "Epoch 5/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.3749 - rmse: 0.6123 - val_loss: 0.2966 - val_rmse: 0.5446\n",
            "Epoch 6/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.3618 - rmse: 0.6015 - val_loss: 0.3617 - val_rmse: 0.6014\n",
            "Epoch 7/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.3189 - rmse: 0.5647 - val_loss: 0.2487 - val_rmse: 0.4987\n",
            "Epoch 8/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2841 - rmse: 0.5330 - val_loss: 0.2932 - val_rmse: 0.5415\n",
            "Epoch 9/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2797 - rmse: 0.5288 - val_loss: 0.2534 - val_rmse: 0.5034\n",
            "Epoch 10/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2653 - rmse: 0.5151 - val_loss: 0.2623 - val_rmse: 0.5122\n",
            "Epoch 11/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2542 - rmse: 0.5042 - val_loss: 0.2512 - val_rmse: 0.5012\n",
            "Epoch 12/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2656 - rmse: 0.5154 - val_loss: 0.2672 - val_rmse: 0.5170\n",
            "Epoch 13/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2537 - rmse: 0.5036 - val_loss: 0.3021 - val_rmse: 0.5496\n",
            "Epoch 14/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2501 - rmse: 0.5001 - val_loss: 0.2925 - val_rmse: 0.5409\n",
            "Epoch 15/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2444 - rmse: 0.4943 - val_loss: 0.2395 - val_rmse: 0.4894\n",
            "Epoch 16/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2483 - rmse: 0.4983 - val_loss: 0.2475 - val_rmse: 0.4975\n",
            "Epoch 17/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2385 - rmse: 0.4884 - val_loss: 0.2398 - val_rmse: 0.4897\n",
            "Epoch 18/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2463 - rmse: 0.4963 - val_loss: 0.2658 - val_rmse: 0.5156\n",
            "Epoch 19/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2410 - rmse: 0.4909 - val_loss: 0.2489 - val_rmse: 0.4989\n",
            "Epoch 20/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2424 - rmse: 0.4923 - val_loss: 0.2403 - val_rmse: 0.4903\n",
            "Epoch 21/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2348 - rmse: 0.4846 - val_loss: 0.2623 - val_rmse: 0.5121\n",
            "Epoch 22/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2397 - rmse: 0.4896 - val_loss: 0.2425 - val_rmse: 0.4925\n",
            "Epoch 23/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2373 - rmse: 0.4872 - val_loss: 0.2573 - val_rmse: 0.5072\n",
            "Epoch 24/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2366 - rmse: 0.4864 - val_loss: 0.2405 - val_rmse: 0.4904\n",
            "Epoch 25/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2348 - rmse: 0.4846 - val_loss: 0.2489 - val_rmse: 0.4989\n",
            "Epoch 26/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2334 - rmse: 0.4831 - val_loss: 0.2516 - val_rmse: 0.5016\n",
            "Epoch 27/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2296 - rmse: 0.4791 - val_loss: 0.2410 - val_rmse: 0.4910\n",
            "Epoch 28/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2309 - rmse: 0.4806 - val_loss: 0.2382 - val_rmse: 0.4881\n",
            "Epoch 29/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2272 - rmse: 0.4766 - val_loss: 0.2420 - val_rmse: 0.4919\n",
            "Epoch 30/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2303 - rmse: 0.4799 - val_loss: 0.2352 - val_rmse: 0.4850\n",
            "Epoch 31/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2237 - rmse: 0.4730 - val_loss: 0.2365 - val_rmse: 0.4864\n",
            "Epoch 32/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2260 - rmse: 0.4754 - val_loss: 0.2438 - val_rmse: 0.4937\n",
            "Epoch 33/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2266 - rmse: 0.4760 - val_loss: 0.2749 - val_rmse: 0.5243\n",
            "Epoch 34/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2265 - rmse: 0.4759 - val_loss: 0.2297 - val_rmse: 0.4792\n",
            "Epoch 35/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2231 - rmse: 0.4723 - val_loss: 0.2349 - val_rmse: 0.4846\n",
            "Epoch 36/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2245 - rmse: 0.4738 - val_loss: 0.2431 - val_rmse: 0.4931\n",
            "Epoch 37/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2230 - rmse: 0.4722 - val_loss: 0.2348 - val_rmse: 0.4846\n",
            "Epoch 38/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2203 - rmse: 0.4693 - val_loss: 0.2285 - val_rmse: 0.4780\n",
            "Epoch 39/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2214 - rmse: 0.4705 - val_loss: 0.2293 - val_rmse: 0.4788\n",
            "Epoch 40/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2195 - rmse: 0.4685 - val_loss: 0.2281 - val_rmse: 0.4776\n",
            "Epoch 41/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2233 - rmse: 0.4725 - val_loss: 0.2275 - val_rmse: 0.4769\n",
            "Epoch 42/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2195 - rmse: 0.4685 - val_loss: 0.2365 - val_rmse: 0.4863\n",
            "Epoch 43/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2170 - rmse: 0.4659 - val_loss: 0.2357 - val_rmse: 0.4855\n",
            "Epoch 44/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2184 - rmse: 0.4673 - val_loss: 0.2369 - val_rmse: 0.4867\n",
            "Epoch 45/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2172 - rmse: 0.4661 - val_loss: 0.2335 - val_rmse: 0.4832\n",
            "Epoch 46/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2152 - rmse: 0.4639 - val_loss: 0.2401 - val_rmse: 0.4900\n",
            "Epoch 47/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2166 - rmse: 0.4654 - val_loss: 0.2313 - val_rmse: 0.4810\n",
            "Epoch 48/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2154 - rmse: 0.4641 - val_loss: 0.2284 - val_rmse: 0.4779\n",
            "Epoch 49/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2146 - rmse: 0.4632 - val_loss: 0.2183 - val_rmse: 0.4672\n",
            "Epoch 50/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2137 - rmse: 0.4623 - val_loss: 0.2182 - val_rmse: 0.4671\n",
            "Epoch 51/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2135 - rmse: 0.4621 - val_loss: 0.2222 - val_rmse: 0.4714\n",
            "Epoch 52/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2111 - rmse: 0.4595 - val_loss: 0.2171 - val_rmse: 0.4660\n",
            "Epoch 53/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2113 - rmse: 0.4597 - val_loss: 0.2317 - val_rmse: 0.4813\n",
            "Epoch 54/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2114 - rmse: 0.4598 - val_loss: 0.2167 - val_rmse: 0.4656\n",
            "Epoch 55/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2092 - rmse: 0.4574 - val_loss: 0.2202 - val_rmse: 0.4692\n",
            "Epoch 56/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2115 - rmse: 0.4599 - val_loss: 0.2167 - val_rmse: 0.4656\n",
            "Epoch 57/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2074 - rmse: 0.4554 - val_loss: 0.2210 - val_rmse: 0.4701\n",
            "Epoch 58/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2095 - rmse: 0.4577 - val_loss: 0.2238 - val_rmse: 0.4731\n",
            "Epoch 59/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2076 - rmse: 0.4557 - val_loss: 0.2110 - val_rmse: 0.4593\n",
            "Epoch 60/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2066 - rmse: 0.4545 - val_loss: 0.2124 - val_rmse: 0.4608\n",
            "Epoch 61/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2076 - rmse: 0.4556 - val_loss: 0.2107 - val_rmse: 0.4590\n",
            "Epoch 62/100\n",
            "620/620 [==============================] - 13s 21ms/step - loss: 0.2055 - rmse: 0.4534 - val_loss: 0.2115 - val_rmse: 0.4599\n",
            "Epoch 63/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2059 - rmse: 0.4537 - val_loss: 0.2085 - val_rmse: 0.4566\n",
            "Epoch 64/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2043 - rmse: 0.4520 - val_loss: 0.2142 - val_rmse: 0.4629\n",
            "Epoch 65/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2029 - rmse: 0.4505 - val_loss: 0.2213 - val_rmse: 0.4704\n",
            "Epoch 66/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2027 - rmse: 0.4502 - val_loss: 0.2231 - val_rmse: 0.4723\n",
            "Epoch 67/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2014 - rmse: 0.4488 - val_loss: 0.2131 - val_rmse: 0.4616\n",
            "Epoch 68/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2002 - rmse: 0.4475 - val_loss: 0.2115 - val_rmse: 0.4598\n",
            "Epoch 69/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.1993 - rmse: 0.4464 - val_loss: 0.2143 - val_rmse: 0.4629\n",
            "Epoch 70/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2006 - rmse: 0.4479 - val_loss: 0.2078 - val_rmse: 0.4559\n",
            "Epoch 71/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.1984 - rmse: 0.4454 - val_loss: 0.2122 - val_rmse: 0.4607\n",
            "Epoch 72/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1968 - rmse: 0.4436 - val_loss: 0.2069 - val_rmse: 0.4549\n",
            "Epoch 73/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1960 - rmse: 0.4427 - val_loss: 0.2031 - val_rmse: 0.4506\n",
            "Epoch 74/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.1959 - rmse: 0.4427 - val_loss: 0.2056 - val_rmse: 0.4534\n",
            "Epoch 75/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1944 - rmse: 0.4409 - val_loss: 0.2128 - val_rmse: 0.4613\n",
            "Epoch 76/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1934 - rmse: 0.4398 - val_loss: 0.1954 - val_rmse: 0.4421\n",
            "Epoch 77/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1926 - rmse: 0.4388 - val_loss: 0.2039 - val_rmse: 0.4515\n",
            "Epoch 78/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1917 - rmse: 0.4378 - val_loss: 0.1912 - val_rmse: 0.4373\n",
            "Epoch 79/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1895 - rmse: 0.4353 - val_loss: 0.2043 - val_rmse: 0.4520\n",
            "Epoch 80/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1892 - rmse: 0.4350 - val_loss: 0.2057 - val_rmse: 0.4535\n",
            "Epoch 81/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1886 - rmse: 0.4342 - val_loss: 0.1989 - val_rmse: 0.4460\n",
            "Epoch 82/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1882 - rmse: 0.4338 - val_loss: 0.1927 - val_rmse: 0.4390\n",
            "Epoch 83/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1848 - rmse: 0.4298 - val_loss: 0.1886 - val_rmse: 0.4343\n",
            "Epoch 84/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1852 - rmse: 0.4304 - val_loss: 0.1936 - val_rmse: 0.4400\n",
            "Epoch 85/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1846 - rmse: 0.4296 - val_loss: 0.1843 - val_rmse: 0.4293\n",
            "Epoch 86/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1825 - rmse: 0.4272 - val_loss: 0.1789 - val_rmse: 0.4230\n",
            "Epoch 87/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1810 - rmse: 0.4254 - val_loss: 0.1852 - val_rmse: 0.4304\n",
            "Epoch 88/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.1785 - rmse: 0.4225 - val_loss: 0.1819 - val_rmse: 0.4264\n",
            "Epoch 89/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1782 - rmse: 0.4222 - val_loss: 0.1780 - val_rmse: 0.4219\n",
            "Epoch 90/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1757 - rmse: 0.4192 - val_loss: 0.1794 - val_rmse: 0.4235\n",
            "Epoch 91/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1758 - rmse: 0.4193 - val_loss: 0.1681 - val_rmse: 0.4100\n",
            "Epoch 92/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1747 - rmse: 0.4179 - val_loss: 0.1746 - val_rmse: 0.4179\n",
            "Epoch 93/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1733 - rmse: 0.4163 - val_loss: 0.1806 - val_rmse: 0.4249\n",
            "Epoch 94/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1715 - rmse: 0.4142 - val_loss: 0.1877 - val_rmse: 0.4332\n",
            "Epoch 95/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1703 - rmse: 0.4126 - val_loss: 0.1610 - val_rmse: 0.4012\n",
            "Epoch 96/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1680 - rmse: 0.4099 - val_loss: 0.1704 - val_rmse: 0.4128\n",
            "Epoch 97/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1678 - rmse: 0.4096 - val_loss: 0.1703 - val_rmse: 0.4127\n",
            "Epoch 98/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1664 - rmse: 0.4079 - val_loss: 0.1701 - val_rmse: 0.4124\n",
            "Epoch 99/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1626 - rmse: 0.4032 - val_loss: 0.1589 - val_rmse: 0.3986\n",
            "Epoch 100/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1637 - rmse: 0.4046 - val_loss: 0.1510 - val_rmse: 0.3886\n",
            "Score for fold 1: loss of 0.1510048806667328; rmse of 38.8593465089798%\n",
            "Epoch 1/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 1.6878 - rmse: 1.2991 - val_loss: 0.2645 - val_rmse: 0.5143\n",
            "Epoch 2/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.4524 - rmse: 0.6726 - val_loss: 0.3257 - val_rmse: 0.5707\n",
            "Epoch 3/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.4187 - rmse: 0.6471 - val_loss: 0.2373 - val_rmse: 0.4872\n",
            "Epoch 4/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.4035 - rmse: 0.6352 - val_loss: 0.2239 - val_rmse: 0.4732\n",
            "Epoch 5/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.3820 - rmse: 0.6181 - val_loss: 0.2275 - val_rmse: 0.4770\n",
            "Epoch 6/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.3702 - rmse: 0.6084 - val_loss: 0.2233 - val_rmse: 0.4725\n",
            "Epoch 7/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.3398 - rmse: 0.5829 - val_loss: 0.2652 - val_rmse: 0.5149\n",
            "Epoch 8/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.3121 - rmse: 0.5586 - val_loss: 0.3455 - val_rmse: 0.5878\n",
            "Epoch 9/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2850 - rmse: 0.5339 - val_loss: 0.3494 - val_rmse: 0.5911\n",
            "Epoch 10/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2627 - rmse: 0.5126 - val_loss: 0.2120 - val_rmse: 0.4604\n",
            "Epoch 11/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2619 - rmse: 0.5117 - val_loss: 0.2238 - val_rmse: 0.4731\n",
            "Epoch 12/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2587 - rmse: 0.5086 - val_loss: 0.2880 - val_rmse: 0.5367\n",
            "Epoch 13/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2564 - rmse: 0.5063 - val_loss: 0.2200 - val_rmse: 0.4690\n",
            "Epoch 14/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2501 - rmse: 0.5001 - val_loss: 0.2228 - val_rmse: 0.4720\n",
            "Epoch 15/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2494 - rmse: 0.4994 - val_loss: 0.2141 - val_rmse: 0.4627\n",
            "Epoch 16/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2469 - rmse: 0.4968 - val_loss: 0.2320 - val_rmse: 0.4817\n",
            "Epoch 17/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2421 - rmse: 0.4920 - val_loss: 0.2361 - val_rmse: 0.4859\n",
            "Epoch 18/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2407 - rmse: 0.4906 - val_loss: 0.2101 - val_rmse: 0.4584\n",
            "Epoch 19/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2379 - rmse: 0.4878 - val_loss: 0.2242 - val_rmse: 0.4735\n",
            "Epoch 20/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2392 - rmse: 0.4891 - val_loss: 0.2332 - val_rmse: 0.4829\n",
            "Epoch 21/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2375 - rmse: 0.4873 - val_loss: 0.2149 - val_rmse: 0.4636\n",
            "Epoch 22/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2381 - rmse: 0.4880 - val_loss: 0.2220 - val_rmse: 0.4712\n",
            "Epoch 23/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2333 - rmse: 0.4830 - val_loss: 0.2378 - val_rmse: 0.4876\n",
            "Epoch 24/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2361 - rmse: 0.4859 - val_loss: 0.2102 - val_rmse: 0.4585\n",
            "Epoch 25/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2310 - rmse: 0.4806 - val_loss: 0.2493 - val_rmse: 0.4993\n",
            "Epoch 26/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2312 - rmse: 0.4808 - val_loss: 0.2172 - val_rmse: 0.4660\n",
            "Epoch 27/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2291 - rmse: 0.4786 - val_loss: 0.2175 - val_rmse: 0.4664\n",
            "Epoch 28/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2274 - rmse: 0.4769 - val_loss: 0.2197 - val_rmse: 0.4687\n",
            "Epoch 29/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2254 - rmse: 0.4747 - val_loss: 0.2296 - val_rmse: 0.4792\n",
            "Epoch 30/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2275 - rmse: 0.4769 - val_loss: 0.2135 - val_rmse: 0.4621\n",
            "Epoch 31/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2272 - rmse: 0.4766 - val_loss: 0.2132 - val_rmse: 0.4618\n",
            "Epoch 32/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2239 - rmse: 0.4732 - val_loss: 0.2134 - val_rmse: 0.4620\n",
            "Epoch 33/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2262 - rmse: 0.4756 - val_loss: 0.2109 - val_rmse: 0.4593\n",
            "Epoch 34/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2266 - rmse: 0.4761 - val_loss: 0.2146 - val_rmse: 0.4632\n",
            "Epoch 35/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2227 - rmse: 0.4719 - val_loss: 0.2138 - val_rmse: 0.4624\n",
            "Epoch 36/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2245 - rmse: 0.4738 - val_loss: 0.2269 - val_rmse: 0.4764\n",
            "Epoch 37/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2215 - rmse: 0.4706 - val_loss: 0.2512 - val_rmse: 0.5011\n",
            "Epoch 38/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2226 - rmse: 0.4718 - val_loss: 0.2000 - val_rmse: 0.4472\n",
            "Epoch 39/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2199 - rmse: 0.4689 - val_loss: 0.2140 - val_rmse: 0.4626\n",
            "Epoch 40/100\n",
            "620/620 [==============================] - 13s 22ms/step - loss: 0.2196 - rmse: 0.4686 - val_loss: 0.2035 - val_rmse: 0.4511\n",
            "Epoch 41/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2187 - rmse: 0.4677 - val_loss: 0.2002 - val_rmse: 0.4474\n",
            "Epoch 42/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2165 - rmse: 0.4652 - val_loss: 0.2086 - val_rmse: 0.4567\n",
            "Epoch 43/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2152 - rmse: 0.4639 - val_loss: 0.1975 - val_rmse: 0.4444\n",
            "Epoch 44/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2170 - rmse: 0.4658 - val_loss: 0.2082 - val_rmse: 0.4563\n",
            "Epoch 45/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2145 - rmse: 0.4631 - val_loss: 0.2020 - val_rmse: 0.4494\n",
            "Epoch 46/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2121 - rmse: 0.4606 - val_loss: 0.2173 - val_rmse: 0.4661\n",
            "Epoch 47/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2144 - rmse: 0.4630 - val_loss: 0.2055 - val_rmse: 0.4533\n",
            "Epoch 48/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2165 - rmse: 0.4653 - val_loss: 0.2002 - val_rmse: 0.4474\n",
            "Epoch 49/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2125 - rmse: 0.4610 - val_loss: 0.1953 - val_rmse: 0.4419\n",
            "Epoch 50/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2123 - rmse: 0.4607 - val_loss: 0.2005 - val_rmse: 0.4478\n",
            "Epoch 51/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2112 - rmse: 0.4595 - val_loss: 0.2026 - val_rmse: 0.4501\n",
            "Epoch 52/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2118 - rmse: 0.4602 - val_loss: 0.1979 - val_rmse: 0.4448\n",
            "Epoch 53/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2108 - rmse: 0.4591 - val_loss: 0.1934 - val_rmse: 0.4398\n",
            "Epoch 54/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2102 - rmse: 0.4585 - val_loss: 0.1963 - val_rmse: 0.4430\n",
            "Epoch 55/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2100 - rmse: 0.4583 - val_loss: 0.2094 - val_rmse: 0.4576\n",
            "Epoch 56/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2083 - rmse: 0.4564 - val_loss: 0.1899 - val_rmse: 0.4357\n",
            "Epoch 57/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2077 - rmse: 0.4558 - val_loss: 0.1998 - val_rmse: 0.4470\n",
            "Epoch 58/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2052 - rmse: 0.4529 - val_loss: 0.2013 - val_rmse: 0.4487\n",
            "Epoch 59/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2051 - rmse: 0.4528 - val_loss: 0.1903 - val_rmse: 0.4362\n",
            "Epoch 60/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2038 - rmse: 0.4515 - val_loss: 0.1905 - val_rmse: 0.4365\n",
            "Epoch 61/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2029 - rmse: 0.4505 - val_loss: 0.2079 - val_rmse: 0.4559\n",
            "Epoch 62/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2043 - rmse: 0.4520 - val_loss: 0.1926 - val_rmse: 0.4388\n",
            "Epoch 63/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2020 - rmse: 0.4495 - val_loss: 0.1931 - val_rmse: 0.4394\n",
            "Epoch 64/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2003 - rmse: 0.4476 - val_loss: 0.1868 - val_rmse: 0.4322\n",
            "Epoch 65/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2012 - rmse: 0.4486 - val_loss: 0.1927 - val_rmse: 0.4390\n",
            "Epoch 66/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2008 - rmse: 0.4481 - val_loss: 0.2166 - val_rmse: 0.4654\n",
            "Epoch 67/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2004 - rmse: 0.4477 - val_loss: 0.1870 - val_rmse: 0.4325\n",
            "Epoch 68/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1991 - rmse: 0.4462 - val_loss: 0.1888 - val_rmse: 0.4345\n",
            "Epoch 69/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1980 - rmse: 0.4449 - val_loss: 0.1891 - val_rmse: 0.4348\n",
            "Epoch 70/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1961 - rmse: 0.4428 - val_loss: 0.1826 - val_rmse: 0.4274\n",
            "Epoch 71/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1953 - rmse: 0.4420 - val_loss: 0.1782 - val_rmse: 0.4221\n",
            "Epoch 72/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1948 - rmse: 0.4413 - val_loss: 0.1864 - val_rmse: 0.4318\n",
            "Epoch 73/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1950 - rmse: 0.4415 - val_loss: 0.1783 - val_rmse: 0.4223\n",
            "Epoch 74/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1911 - rmse: 0.4372 - val_loss: 0.1761 - val_rmse: 0.4196\n",
            "Epoch 75/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1912 - rmse: 0.4372 - val_loss: 0.2169 - val_rmse: 0.4657\n",
            "Epoch 76/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1896 - rmse: 0.4354 - val_loss: 0.1761 - val_rmse: 0.4197\n",
            "Epoch 77/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1911 - rmse: 0.4372 - val_loss: 0.1742 - val_rmse: 0.4173\n",
            "Epoch 78/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1866 - rmse: 0.4320 - val_loss: 0.1826 - val_rmse: 0.4273\n",
            "Epoch 79/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1863 - rmse: 0.4317 - val_loss: 0.1701 - val_rmse: 0.4125\n",
            "Epoch 80/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1851 - rmse: 0.4303 - val_loss: 0.1754 - val_rmse: 0.4189\n",
            "Epoch 81/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1861 - rmse: 0.4314 - val_loss: 0.1790 - val_rmse: 0.4231\n",
            "Epoch 82/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1828 - rmse: 0.4276 - val_loss: 0.1976 - val_rmse: 0.4445\n",
            "Epoch 83/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1824 - rmse: 0.4270 - val_loss: 0.1639 - val_rmse: 0.4048\n",
            "Epoch 84/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1783 - rmse: 0.4223 - val_loss: 0.1676 - val_rmse: 0.4093\n",
            "Epoch 85/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1785 - rmse: 0.4225 - val_loss: 0.1650 - val_rmse: 0.4062\n",
            "Epoch 86/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1793 - rmse: 0.4234 - val_loss: 0.1631 - val_rmse: 0.4039\n",
            "Epoch 87/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1749 - rmse: 0.4183 - val_loss: 0.1711 - val_rmse: 0.4136\n",
            "Epoch 88/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1740 - rmse: 0.4171 - val_loss: 0.1629 - val_rmse: 0.4036\n",
            "Epoch 89/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1733 - rmse: 0.4163 - val_loss: 0.1763 - val_rmse: 0.4199\n",
            "Epoch 90/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1725 - rmse: 0.4153 - val_loss: 0.1673 - val_rmse: 0.4090\n",
            "Epoch 91/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1694 - rmse: 0.4116 - val_loss: 0.1598 - val_rmse: 0.3998\n",
            "Epoch 92/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1691 - rmse: 0.4112 - val_loss: 0.1592 - val_rmse: 0.3990\n",
            "Epoch 93/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1668 - rmse: 0.4084 - val_loss: 0.1672 - val_rmse: 0.4089\n",
            "Epoch 94/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1671 - rmse: 0.4088 - val_loss: 0.1508 - val_rmse: 0.3883\n",
            "Epoch 95/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1616 - rmse: 0.4020 - val_loss: 0.1541 - val_rmse: 0.3926\n",
            "Epoch 96/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1620 - rmse: 0.4025 - val_loss: 0.1508 - val_rmse: 0.3884\n",
            "Epoch 97/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1607 - rmse: 0.4008 - val_loss: 0.1684 - val_rmse: 0.4104\n",
            "Epoch 98/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1602 - rmse: 0.4002 - val_loss: 0.1594 - val_rmse: 0.3993\n",
            "Epoch 99/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1586 - rmse: 0.3983 - val_loss: 0.1477 - val_rmse: 0.3844\n",
            "Epoch 100/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1547 - rmse: 0.3933 - val_loss: 0.1414 - val_rmse: 0.3760\n",
            "Score for fold 2: loss of 0.14140722155570984; rmse of 37.60415017604828%\n",
            "Epoch 1/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 1.9124 - rmse: 1.3829 - val_loss: 0.4314 - val_rmse: 0.6568\n",
            "Epoch 2/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.4554 - rmse: 0.6748 - val_loss: 0.2711 - val_rmse: 0.5207\n",
            "Epoch 3/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.4287 - rmse: 0.6548 - val_loss: 0.2561 - val_rmse: 0.5061\n",
            "Epoch 4/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.4017 - rmse: 0.6338 - val_loss: 0.3393 - val_rmse: 0.5825\n",
            "Epoch 5/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.4065 - rmse: 0.6376 - val_loss: 0.2479 - val_rmse: 0.4979\n",
            "Epoch 6/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.3684 - rmse: 0.6070 - val_loss: 0.2341 - val_rmse: 0.4839\n",
            "Epoch 7/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.3343 - rmse: 0.5782 - val_loss: 0.2396 - val_rmse: 0.4895\n",
            "Epoch 8/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.3018 - rmse: 0.5493 - val_loss: 0.2472 - val_rmse: 0.4972\n",
            "Epoch 9/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2809 - rmse: 0.5300 - val_loss: 0.2458 - val_rmse: 0.4958\n",
            "Epoch 10/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2676 - rmse: 0.5173 - val_loss: 0.2616 - val_rmse: 0.5115\n",
            "Epoch 11/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2658 - rmse: 0.5155 - val_loss: 0.2274 - val_rmse: 0.4769\n",
            "Epoch 12/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2584 - rmse: 0.5083 - val_loss: 0.2230 - val_rmse: 0.4723\n",
            "Epoch 13/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2504 - rmse: 0.5004 - val_loss: 0.2474 - val_rmse: 0.4974\n",
            "Epoch 14/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2497 - rmse: 0.4997 - val_loss: 0.2459 - val_rmse: 0.4958\n",
            "Epoch 15/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2510 - rmse: 0.5010 - val_loss: 0.2173 - val_rmse: 0.4662\n",
            "Epoch 16/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2388 - rmse: 0.4887 - val_loss: 0.2173 - val_rmse: 0.4662\n",
            "Epoch 17/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2430 - rmse: 0.4930 - val_loss: 0.2141 - val_rmse: 0.4627\n",
            "Epoch 18/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2424 - rmse: 0.4923 - val_loss: 0.2341 - val_rmse: 0.4838\n",
            "Epoch 19/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2399 - rmse: 0.4898 - val_loss: 0.2310 - val_rmse: 0.4806\n",
            "Epoch 20/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2385 - rmse: 0.4884 - val_loss: 0.2152 - val_rmse: 0.4639\n",
            "Epoch 21/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2378 - rmse: 0.4877 - val_loss: 0.2165 - val_rmse: 0.4653\n",
            "Epoch 22/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2341 - rmse: 0.4838 - val_loss: 0.2465 - val_rmse: 0.4965\n",
            "Epoch 23/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2339 - rmse: 0.4836 - val_loss: 0.2153 - val_rmse: 0.4640\n",
            "Epoch 24/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2360 - rmse: 0.4858 - val_loss: 0.2179 - val_rmse: 0.4668\n",
            "Epoch 25/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2331 - rmse: 0.4828 - val_loss: 0.2148 - val_rmse: 0.4634\n",
            "Epoch 26/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2328 - rmse: 0.4825 - val_loss: 0.2178 - val_rmse: 0.4667\n",
            "Epoch 27/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2323 - rmse: 0.4820 - val_loss: 0.2094 - val_rmse: 0.4576\n",
            "Epoch 28/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2262 - rmse: 0.4757 - val_loss: 0.2204 - val_rmse: 0.4695\n",
            "Epoch 29/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2303 - rmse: 0.4799 - val_loss: 0.2141 - val_rmse: 0.4627\n",
            "Epoch 30/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2265 - rmse: 0.4760 - val_loss: 0.2265 - val_rmse: 0.4759\n",
            "Epoch 31/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2273 - rmse: 0.4767 - val_loss: 0.2154 - val_rmse: 0.4641\n",
            "Epoch 32/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2293 - rmse: 0.4788 - val_loss: 0.2516 - val_rmse: 0.5016\n",
            "Epoch 33/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2249 - rmse: 0.4742 - val_loss: 0.2364 - val_rmse: 0.4862\n",
            "Epoch 34/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2291 - rmse: 0.4786 - val_loss: 0.2222 - val_rmse: 0.4714\n",
            "Epoch 35/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2243 - rmse: 0.4736 - val_loss: 0.2138 - val_rmse: 0.4624\n",
            "Epoch 36/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2236 - rmse: 0.4728 - val_loss: 0.2176 - val_rmse: 0.4665\n",
            "Epoch 37/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2241 - rmse: 0.4734 - val_loss: 0.2224 - val_rmse: 0.4716\n",
            "Epoch 38/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2196 - rmse: 0.4686 - val_loss: 0.2196 - val_rmse: 0.4686\n",
            "Epoch 39/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2219 - rmse: 0.4710 - val_loss: 0.2080 - val_rmse: 0.4561\n",
            "Epoch 40/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2203 - rmse: 0.4693 - val_loss: 0.2180 - val_rmse: 0.4669\n",
            "Epoch 41/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2200 - rmse: 0.4690 - val_loss: 0.2072 - val_rmse: 0.4552\n",
            "Epoch 42/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2181 - rmse: 0.4670 - val_loss: 0.2122 - val_rmse: 0.4607\n",
            "Epoch 43/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2180 - rmse: 0.4669 - val_loss: 0.2017 - val_rmse: 0.4491\n",
            "Epoch 44/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2178 - rmse: 0.4667 - val_loss: 0.2043 - val_rmse: 0.4520\n",
            "Epoch 45/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2173 - rmse: 0.4662 - val_loss: 0.2178 - val_rmse: 0.4667\n",
            "Epoch 46/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2158 - rmse: 0.4646 - val_loss: 0.2142 - val_rmse: 0.4629\n",
            "Epoch 47/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2174 - rmse: 0.4663 - val_loss: 0.2031 - val_rmse: 0.4507\n",
            "Epoch 48/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2161 - rmse: 0.4648 - val_loss: 0.2125 - val_rmse: 0.4610\n",
            "Epoch 49/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2126 - rmse: 0.4611 - val_loss: 0.2117 - val_rmse: 0.4601\n",
            "Epoch 50/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2133 - rmse: 0.4618 - val_loss: 0.2177 - val_rmse: 0.4666\n",
            "Epoch 51/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2108 - rmse: 0.4591 - val_loss: 0.2132 - val_rmse: 0.4617\n",
            "Epoch 52/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2123 - rmse: 0.4608 - val_loss: 0.2089 - val_rmse: 0.4571\n",
            "Epoch 53/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2121 - rmse: 0.4605 - val_loss: 0.2159 - val_rmse: 0.4646\n",
            "Epoch 54/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2094 - rmse: 0.4576 - val_loss: 0.1982 - val_rmse: 0.4451\n",
            "Epoch 55/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2096 - rmse: 0.4578 - val_loss: 0.2225 - val_rmse: 0.4717\n",
            "Epoch 56/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2095 - rmse: 0.4577 - val_loss: 0.2152 - val_rmse: 0.4639\n",
            "Epoch 57/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2077 - rmse: 0.4557 - val_loss: 0.2077 - val_rmse: 0.4557\n",
            "Epoch 58/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2082 - rmse: 0.4563 - val_loss: 0.1971 - val_rmse: 0.4440\n",
            "Epoch 59/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2070 - rmse: 0.4550 - val_loss: 0.2087 - val_rmse: 0.4569\n",
            "Epoch 60/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2069 - rmse: 0.4549 - val_loss: 0.2009 - val_rmse: 0.4482\n",
            "Epoch 61/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2083 - rmse: 0.4564 - val_loss: 0.2232 - val_rmse: 0.4724\n",
            "Epoch 62/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2051 - rmse: 0.4529 - val_loss: 0.2057 - val_rmse: 0.4536\n",
            "Epoch 63/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2050 - rmse: 0.4527 - val_loss: 0.1923 - val_rmse: 0.4385\n",
            "Epoch 64/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2049 - rmse: 0.4527 - val_loss: 0.2103 - val_rmse: 0.4585\n",
            "Epoch 65/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2050 - rmse: 0.4527 - val_loss: 0.1966 - val_rmse: 0.4434\n",
            "Epoch 66/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2029 - rmse: 0.4504 - val_loss: 0.1953 - val_rmse: 0.4420\n",
            "Epoch 67/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2017 - rmse: 0.4491 - val_loss: 0.2063 - val_rmse: 0.4542\n",
            "Epoch 68/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1997 - rmse: 0.4469 - val_loss: 0.2016 - val_rmse: 0.4490\n",
            "Epoch 69/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1985 - rmse: 0.4455 - val_loss: 0.1888 - val_rmse: 0.4345\n",
            "Epoch 70/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1979 - rmse: 0.4449 - val_loss: 0.1881 - val_rmse: 0.4337\n",
            "Epoch 71/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1971 - rmse: 0.4439 - val_loss: 0.1936 - val_rmse: 0.4400\n",
            "Epoch 72/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1973 - rmse: 0.4442 - val_loss: 0.1869 - val_rmse: 0.4324\n",
            "Epoch 73/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1944 - rmse: 0.4409 - val_loss: 0.1891 - val_rmse: 0.4349\n",
            "Epoch 74/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1943 - rmse: 0.4407 - val_loss: 0.1892 - val_rmse: 0.4349\n",
            "Epoch 75/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1914 - rmse: 0.4375 - val_loss: 0.1843 - val_rmse: 0.4293\n",
            "Epoch 76/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1920 - rmse: 0.4382 - val_loss: 0.1894 - val_rmse: 0.4352\n",
            "Epoch 77/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1907 - rmse: 0.4367 - val_loss: 0.1808 - val_rmse: 0.4252\n",
            "Epoch 78/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1903 - rmse: 0.4363 - val_loss: 0.1856 - val_rmse: 0.4308\n",
            "Epoch 79/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1897 - rmse: 0.4355 - val_loss: 0.1861 - val_rmse: 0.4313\n",
            "Epoch 80/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1896 - rmse: 0.4354 - val_loss: 0.1814 - val_rmse: 0.4259\n",
            "Epoch 81/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1871 - rmse: 0.4326 - val_loss: 0.1806 - val_rmse: 0.4250\n",
            "Epoch 82/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1857 - rmse: 0.4309 - val_loss: 0.1760 - val_rmse: 0.4196\n",
            "Epoch 83/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1841 - rmse: 0.4291 - val_loss: 0.1724 - val_rmse: 0.4152\n",
            "Epoch 84/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1839 - rmse: 0.4288 - val_loss: 0.1746 - val_rmse: 0.4179\n",
            "Epoch 85/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1817 - rmse: 0.4263 - val_loss: 0.1742 - val_rmse: 0.4173\n",
            "Epoch 86/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1822 - rmse: 0.4268 - val_loss: 0.1717 - val_rmse: 0.4143\n",
            "Epoch 87/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1771 - rmse: 0.4208 - val_loss: 0.1746 - val_rmse: 0.4178\n",
            "Epoch 88/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1771 - rmse: 0.4209 - val_loss: 0.1838 - val_rmse: 0.4287\n",
            "Epoch 89/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1751 - rmse: 0.4185 - val_loss: 0.1710 - val_rmse: 0.4135\n",
            "Epoch 90/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1750 - rmse: 0.4183 - val_loss: 0.1753 - val_rmse: 0.4187\n",
            "Epoch 91/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1729 - rmse: 0.4158 - val_loss: 0.1734 - val_rmse: 0.4164\n",
            "Epoch 92/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1726 - rmse: 0.4154 - val_loss: 0.1720 - val_rmse: 0.4148\n",
            "Epoch 93/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1703 - rmse: 0.4126 - val_loss: 0.1629 - val_rmse: 0.4036\n",
            "Epoch 94/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1679 - rmse: 0.4098 - val_loss: 0.1780 - val_rmse: 0.4219\n",
            "Epoch 95/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1702 - rmse: 0.4126 - val_loss: 0.1759 - val_rmse: 0.4194\n",
            "Epoch 96/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1675 - rmse: 0.4093 - val_loss: 0.1623 - val_rmse: 0.4029\n",
            "Epoch 97/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1641 - rmse: 0.4051 - val_loss: 0.1557 - val_rmse: 0.3946\n",
            "Epoch 98/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1644 - rmse: 0.4055 - val_loss: 0.1534 - val_rmse: 0.3916\n",
            "Epoch 99/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1613 - rmse: 0.4017 - val_loss: 0.1532 - val_rmse: 0.3914\n",
            "Epoch 100/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1606 - rmse: 0.4008 - val_loss: 0.1500 - val_rmse: 0.3873\n",
            "Score for fold 3: loss of 0.15003830194473267; rmse of 38.73477876186371%\n",
            "Epoch 1/100\n",
            "620/620 [==============================] - 15s 23ms/step - loss: 2.6274 - rmse: 1.6209 - val_loss: 0.3155 - val_rmse: 0.5617\n",
            "Epoch 2/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.4710 - rmse: 0.6863 - val_loss: 0.2650 - val_rmse: 0.5147\n",
            "Epoch 3/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.4390 - rmse: 0.6625 - val_loss: 0.2895 - val_rmse: 0.5380\n",
            "Epoch 4/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.4315 - rmse: 0.6569 - val_loss: 0.2596 - val_rmse: 0.5095\n",
            "Epoch 5/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.4086 - rmse: 0.6392 - val_loss: 0.2583 - val_rmse: 0.5082\n",
            "Epoch 6/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.3860 - rmse: 0.6213 - val_loss: 0.2798 - val_rmse: 0.5289\n",
            "Epoch 7/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.3658 - rmse: 0.6048 - val_loss: 0.3091 - val_rmse: 0.5559\n",
            "Epoch 8/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.3295 - rmse: 0.5740 - val_loss: 0.2991 - val_rmse: 0.5469\n",
            "Epoch 9/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2877 - rmse: 0.5363 - val_loss: 0.2369 - val_rmse: 0.4867\n",
            "Epoch 10/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2770 - rmse: 0.5264 - val_loss: 0.3112 - val_rmse: 0.5579\n",
            "Epoch 11/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2630 - rmse: 0.5129 - val_loss: 0.2443 - val_rmse: 0.4943\n",
            "Epoch 12/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2633 - rmse: 0.5131 - val_loss: 0.2551 - val_rmse: 0.5051\n",
            "Epoch 13/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2575 - rmse: 0.5074 - val_loss: 0.2417 - val_rmse: 0.4916\n",
            "Epoch 14/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2472 - rmse: 0.4972 - val_loss: 0.3236 - val_rmse: 0.5688\n",
            "Epoch 15/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2545 - rmse: 0.5044 - val_loss: 0.2708 - val_rmse: 0.5204\n",
            "Epoch 16/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2451 - rmse: 0.4951 - val_loss: 0.2915 - val_rmse: 0.5399\n",
            "Epoch 17/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2428 - rmse: 0.4928 - val_loss: 0.2453 - val_rmse: 0.4953\n",
            "Epoch 18/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2406 - rmse: 0.4905 - val_loss: 0.2362 - val_rmse: 0.4860\n",
            "Epoch 19/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2422 - rmse: 0.4921 - val_loss: 0.2420 - val_rmse: 0.4919\n",
            "Epoch 20/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2412 - rmse: 0.4911 - val_loss: 0.2305 - val_rmse: 0.4801\n",
            "Epoch 21/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2384 - rmse: 0.4883 - val_loss: 0.2338 - val_rmse: 0.4836\n",
            "Epoch 22/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2378 - rmse: 0.4877 - val_loss: 0.2681 - val_rmse: 0.5177\n",
            "Epoch 23/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2384 - rmse: 0.4883 - val_loss: 0.2363 - val_rmse: 0.4861\n",
            "Epoch 24/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2320 - rmse: 0.4817 - val_loss: 0.2294 - val_rmse: 0.4789\n",
            "Epoch 25/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2321 - rmse: 0.4818 - val_loss: 0.2353 - val_rmse: 0.4850\n",
            "Epoch 26/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2333 - rmse: 0.4830 - val_loss: 0.2335 - val_rmse: 0.4832\n",
            "Epoch 27/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2279 - rmse: 0.4773 - val_loss: 0.2422 - val_rmse: 0.4922\n",
            "Epoch 28/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2261 - rmse: 0.4755 - val_loss: 0.2444 - val_rmse: 0.4944\n",
            "Epoch 29/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2304 - rmse: 0.4800 - val_loss: 0.2442 - val_rmse: 0.4942\n",
            "Epoch 30/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2275 - rmse: 0.4769 - val_loss: 0.2273 - val_rmse: 0.4767\n",
            "Epoch 31/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2272 - rmse: 0.4767 - val_loss: 0.2373 - val_rmse: 0.4871\n",
            "Epoch 32/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2249 - rmse: 0.4743 - val_loss: 0.2283 - val_rmse: 0.4778\n",
            "Epoch 33/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2272 - rmse: 0.4767 - val_loss: 0.2511 - val_rmse: 0.5011\n",
            "Epoch 34/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2287 - rmse: 0.4782 - val_loss: 0.2373 - val_rmse: 0.4871\n",
            "Epoch 35/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2251 - rmse: 0.4744 - val_loss: 0.2422 - val_rmse: 0.4921\n",
            "Epoch 36/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2230 - rmse: 0.4722 - val_loss: 0.2276 - val_rmse: 0.4771\n",
            "Epoch 37/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2243 - rmse: 0.4736 - val_loss: 0.2305 - val_rmse: 0.4801\n",
            "Epoch 38/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2266 - rmse: 0.4760 - val_loss: 0.2273 - val_rmse: 0.4767\n",
            "Epoch 39/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2213 - rmse: 0.4704 - val_loss: 0.2286 - val_rmse: 0.4782\n",
            "Epoch 40/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2197 - rmse: 0.4687 - val_loss: 0.2286 - val_rmse: 0.4781\n",
            "Epoch 41/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2199 - rmse: 0.4690 - val_loss: 0.2210 - val_rmse: 0.4701\n",
            "Epoch 42/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2189 - rmse: 0.4679 - val_loss: 0.2367 - val_rmse: 0.4865\n",
            "Epoch 43/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2175 - rmse: 0.4664 - val_loss: 0.2300 - val_rmse: 0.4796\n",
            "Epoch 44/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2183 - rmse: 0.4672 - val_loss: 0.2468 - val_rmse: 0.4968\n",
            "Epoch 45/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2186 - rmse: 0.4675 - val_loss: 0.2359 - val_rmse: 0.4857\n",
            "Epoch 46/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2178 - rmse: 0.4667 - val_loss: 0.2333 - val_rmse: 0.4830\n",
            "Epoch 47/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2156 - rmse: 0.4644 - val_loss: 0.2198 - val_rmse: 0.4688\n",
            "Epoch 48/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2157 - rmse: 0.4644 - val_loss: 0.2188 - val_rmse: 0.4678\n",
            "Epoch 49/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2151 - rmse: 0.4638 - val_loss: 0.2280 - val_rmse: 0.4775\n",
            "Epoch 50/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2132 - rmse: 0.4617 - val_loss: 0.2198 - val_rmse: 0.4688\n",
            "Epoch 51/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2135 - rmse: 0.4620 - val_loss: 0.2173 - val_rmse: 0.4661\n",
            "Epoch 52/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2115 - rmse: 0.4599 - val_loss: 0.2170 - val_rmse: 0.4658\n",
            "Epoch 53/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2120 - rmse: 0.4604 - val_loss: 0.2157 - val_rmse: 0.4645\n",
            "Epoch 54/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2110 - rmse: 0.4594 - val_loss: 0.2194 - val_rmse: 0.4684\n",
            "Epoch 55/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2127 - rmse: 0.4612 - val_loss: 0.2172 - val_rmse: 0.4661\n",
            "Epoch 56/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2105 - rmse: 0.4588 - val_loss: 0.2147 - val_rmse: 0.4633\n",
            "Epoch 57/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2083 - rmse: 0.4564 - val_loss: 0.2180 - val_rmse: 0.4669\n",
            "Epoch 58/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2081 - rmse: 0.4562 - val_loss: 0.2272 - val_rmse: 0.4767\n",
            "Epoch 59/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2059 - rmse: 0.4538 - val_loss: 0.2110 - val_rmse: 0.4594\n",
            "Epoch 60/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2076 - rmse: 0.4556 - val_loss: 0.2306 - val_rmse: 0.4802\n",
            "Epoch 61/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2053 - rmse: 0.4531 - val_loss: 0.2145 - val_rmse: 0.4631\n",
            "Epoch 62/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2055 - rmse: 0.4533 - val_loss: 0.2153 - val_rmse: 0.4640\n",
            "Epoch 63/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2051 - rmse: 0.4529 - val_loss: 0.2113 - val_rmse: 0.4596\n",
            "Epoch 64/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2036 - rmse: 0.4512 - val_loss: 0.2155 - val_rmse: 0.4642\n",
            "Epoch 65/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2036 - rmse: 0.4512 - val_loss: 0.2082 - val_rmse: 0.4563\n",
            "Epoch 66/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2038 - rmse: 0.4515 - val_loss: 0.2108 - val_rmse: 0.4592\n",
            "Epoch 67/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2032 - rmse: 0.4508 - val_loss: 0.2035 - val_rmse: 0.4511\n",
            "Epoch 68/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1997 - rmse: 0.4469 - val_loss: 0.2107 - val_rmse: 0.4590\n",
            "Epoch 69/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1998 - rmse: 0.4470 - val_loss: 0.2093 - val_rmse: 0.4575\n",
            "Epoch 70/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2006 - rmse: 0.4479 - val_loss: 0.2056 - val_rmse: 0.4534\n",
            "Epoch 71/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1991 - rmse: 0.4462 - val_loss: 0.2094 - val_rmse: 0.4576\n",
            "Epoch 72/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1964 - rmse: 0.4432 - val_loss: 0.2059 - val_rmse: 0.4537\n",
            "Epoch 73/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1970 - rmse: 0.4438 - val_loss: 0.2030 - val_rmse: 0.4505\n",
            "Epoch 74/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1961 - rmse: 0.4428 - val_loss: 0.2043 - val_rmse: 0.4520\n",
            "Epoch 75/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1949 - rmse: 0.4414 - val_loss: 0.2012 - val_rmse: 0.4485\n",
            "Epoch 76/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1943 - rmse: 0.4407 - val_loss: 0.2073 - val_rmse: 0.4553\n",
            "Epoch 77/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1935 - rmse: 0.4399 - val_loss: 0.1973 - val_rmse: 0.4442\n",
            "Epoch 78/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1927 - rmse: 0.4389 - val_loss: 0.1959 - val_rmse: 0.4426\n",
            "Epoch 79/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1888 - rmse: 0.4345 - val_loss: 0.2050 - val_rmse: 0.4527\n",
            "Epoch 80/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1889 - rmse: 0.4346 - val_loss: 0.1932 - val_rmse: 0.4395\n",
            "Epoch 81/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1888 - rmse: 0.4345 - val_loss: 0.1980 - val_rmse: 0.4450\n",
            "Epoch 82/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1898 - rmse: 0.4356 - val_loss: 0.2043 - val_rmse: 0.4519\n",
            "Epoch 83/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1878 - rmse: 0.4334 - val_loss: 0.1882 - val_rmse: 0.4338\n",
            "Epoch 84/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1858 - rmse: 0.4310 - val_loss: 0.1906 - val_rmse: 0.4366\n",
            "Epoch 85/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1844 - rmse: 0.4294 - val_loss: 0.1936 - val_rmse: 0.4400\n",
            "Epoch 86/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1828 - rmse: 0.4275 - val_loss: 0.1841 - val_rmse: 0.4291\n",
            "Epoch 87/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1801 - rmse: 0.4243 - val_loss: 0.1913 - val_rmse: 0.4374\n",
            "Epoch 88/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1793 - rmse: 0.4234 - val_loss: 0.1883 - val_rmse: 0.4339\n",
            "Epoch 89/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1809 - rmse: 0.4253 - val_loss: 0.1828 - val_rmse: 0.4276\n",
            "Epoch 90/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1784 - rmse: 0.4224 - val_loss: 0.1875 - val_rmse: 0.4330\n",
            "Epoch 91/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1751 - rmse: 0.4185 - val_loss: 0.1762 - val_rmse: 0.4198\n",
            "Epoch 92/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.1751 - rmse: 0.4185 - val_loss: 0.1789 - val_rmse: 0.4230\n",
            "Epoch 93/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1743 - rmse: 0.4175 - val_loss: 0.1788 - val_rmse: 0.4228\n",
            "Epoch 94/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1723 - rmse: 0.4151 - val_loss: 0.1811 - val_rmse: 0.4255\n",
            "Epoch 95/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1706 - rmse: 0.4130 - val_loss: 0.1771 - val_rmse: 0.4209\n",
            "Epoch 96/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1688 - rmse: 0.4108 - val_loss: 0.1737 - val_rmse: 0.4168\n",
            "Epoch 97/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1689 - rmse: 0.4109 - val_loss: 0.1760 - val_rmse: 0.4195\n",
            "Epoch 98/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1659 - rmse: 0.4074 - val_loss: 0.1662 - val_rmse: 0.4077\n",
            "Epoch 99/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1662 - rmse: 0.4077 - val_loss: 0.1657 - val_rmse: 0.4071\n",
            "Epoch 100/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1624 - rmse: 0.4030 - val_loss: 0.1659 - val_rmse: 0.4073\n",
            "Score for fold 4: loss of 0.16590291261672974; rmse of 40.73118269443512%\n",
            "Epoch 1/100\n",
            "620/620 [==============================] - 15s 23ms/step - loss: 2.2585 - rmse: 1.5028 - val_loss: 0.3742 - val_rmse: 0.6117\n",
            "Epoch 2/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.4839 - rmse: 0.6956 - val_loss: 0.2375 - val_rmse: 0.4874\n",
            "Epoch 3/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.4200 - rmse: 0.6481 - val_loss: 0.2134 - val_rmse: 0.4619\n",
            "Epoch 4/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.4065 - rmse: 0.6376 - val_loss: 0.2882 - val_rmse: 0.5368\n",
            "Epoch 5/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.3942 - rmse: 0.6279 - val_loss: 0.2146 - val_rmse: 0.4633\n",
            "Epoch 6/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.3741 - rmse: 0.6116 - val_loss: 0.2111 - val_rmse: 0.4595\n",
            "Epoch 7/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.3453 - rmse: 0.5876 - val_loss: 0.2266 - val_rmse: 0.4760\n",
            "Epoch 8/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.3180 - rmse: 0.5640 - val_loss: 0.1986 - val_rmse: 0.4457\n",
            "Epoch 9/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2786 - rmse: 0.5278 - val_loss: 0.2023 - val_rmse: 0.4498\n",
            "Epoch 10/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2673 - rmse: 0.5170 - val_loss: 0.3318 - val_rmse: 0.5760\n",
            "Epoch 11/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2567 - rmse: 0.5066 - val_loss: 0.1979 - val_rmse: 0.4448\n",
            "Epoch 12/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2570 - rmse: 0.5070 - val_loss: 0.2431 - val_rmse: 0.4930\n",
            "Epoch 13/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2523 - rmse: 0.5022 - val_loss: 0.2092 - val_rmse: 0.4574\n",
            "Epoch 14/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2473 - rmse: 0.4973 - val_loss: 0.1945 - val_rmse: 0.4410\n",
            "Epoch 15/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2480 - rmse: 0.4980 - val_loss: 0.1918 - val_rmse: 0.4380\n",
            "Epoch 16/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2428 - rmse: 0.4927 - val_loss: 0.2051 - val_rmse: 0.4528\n",
            "Epoch 17/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2438 - rmse: 0.4938 - val_loss: 0.2527 - val_rmse: 0.5027\n",
            "Epoch 18/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2436 - rmse: 0.4935 - val_loss: 0.2062 - val_rmse: 0.4541\n",
            "Epoch 19/100\n",
            "620/620 [==============================] - 14s 22ms/step - loss: 0.2431 - rmse: 0.4931 - val_loss: 0.1906 - val_rmse: 0.4365\n",
            "Epoch 20/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2404 - rmse: 0.4903 - val_loss: 0.2037 - val_rmse: 0.4513\n",
            "Epoch 21/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2381 - rmse: 0.4880 - val_loss: 0.1951 - val_rmse: 0.4417\n",
            "Epoch 22/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2369 - rmse: 0.4867 - val_loss: 0.1920 - val_rmse: 0.4382\n",
            "Epoch 23/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2314 - rmse: 0.4810 - val_loss: 0.2216 - val_rmse: 0.4708\n",
            "Epoch 24/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2349 - rmse: 0.4847 - val_loss: 0.2421 - val_rmse: 0.4921\n",
            "Epoch 25/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2292 - rmse: 0.4788 - val_loss: 0.2006 - val_rmse: 0.4479\n",
            "Epoch 26/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2297 - rmse: 0.4792 - val_loss: 0.1928 - val_rmse: 0.4391\n",
            "Epoch 27/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2297 - rmse: 0.4792 - val_loss: 0.2137 - val_rmse: 0.4623\n",
            "Epoch 28/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2319 - rmse: 0.4815 - val_loss: 0.1918 - val_rmse: 0.4380\n",
            "Epoch 29/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2292 - rmse: 0.4787 - val_loss: 0.2032 - val_rmse: 0.4508\n",
            "Epoch 30/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2269 - rmse: 0.4763 - val_loss: 0.1924 - val_rmse: 0.4386\n",
            "Epoch 31/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2292 - rmse: 0.4787 - val_loss: 0.1906 - val_rmse: 0.4366\n",
            "Epoch 32/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2250 - rmse: 0.4743 - val_loss: 0.1894 - val_rmse: 0.4352\n",
            "Epoch 33/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2259 - rmse: 0.4753 - val_loss: 0.2083 - val_rmse: 0.4564\n",
            "Epoch 34/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2230 - rmse: 0.4722 - val_loss: 0.1914 - val_rmse: 0.4375\n",
            "Epoch 35/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2240 - rmse: 0.4733 - val_loss: 0.1975 - val_rmse: 0.4444\n",
            "Epoch 36/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2214 - rmse: 0.4706 - val_loss: 0.2129 - val_rmse: 0.4614\n",
            "Epoch 37/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2224 - rmse: 0.4716 - val_loss: 0.1896 - val_rmse: 0.4355\n",
            "Epoch 38/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2213 - rmse: 0.4704 - val_loss: 0.2001 - val_rmse: 0.4473\n",
            "Epoch 39/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2210 - rmse: 0.4701 - val_loss: 0.1840 - val_rmse: 0.4289\n",
            "Epoch 40/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2199 - rmse: 0.4690 - val_loss: 0.1902 - val_rmse: 0.4361\n",
            "Epoch 41/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2222 - rmse: 0.4714 - val_loss: 0.1870 - val_rmse: 0.4324\n",
            "Epoch 42/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2188 - rmse: 0.4678 - val_loss: 0.1928 - val_rmse: 0.4391\n",
            "Epoch 43/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2172 - rmse: 0.4661 - val_loss: 0.1819 - val_rmse: 0.4265\n",
            "Epoch 44/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2182 - rmse: 0.4671 - val_loss: 0.1913 - val_rmse: 0.4373\n",
            "Epoch 45/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2149 - rmse: 0.4636 - val_loss: 0.1964 - val_rmse: 0.4432\n",
            "Epoch 46/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2154 - rmse: 0.4641 - val_loss: 0.1927 - val_rmse: 0.4390\n",
            "Epoch 47/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2144 - rmse: 0.4630 - val_loss: 0.2017 - val_rmse: 0.4492\n",
            "Epoch 48/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2140 - rmse: 0.4626 - val_loss: 0.1900 - val_rmse: 0.4359\n",
            "Epoch 49/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2137 - rmse: 0.4622 - val_loss: 0.1928 - val_rmse: 0.4391\n",
            "Epoch 50/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2134 - rmse: 0.4619 - val_loss: 0.1860 - val_rmse: 0.4313\n",
            "Epoch 51/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2117 - rmse: 0.4601 - val_loss: 0.1798 - val_rmse: 0.4240\n",
            "Epoch 52/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2105 - rmse: 0.4588 - val_loss: 0.1812 - val_rmse: 0.4257\n",
            "Epoch 53/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2113 - rmse: 0.4597 - val_loss: 0.1797 - val_rmse: 0.4240\n",
            "Epoch 54/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2113 - rmse: 0.4597 - val_loss: 0.1860 - val_rmse: 0.4313\n",
            "Epoch 55/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2101 - rmse: 0.4584 - val_loss: 0.1875 - val_rmse: 0.4330\n",
            "Epoch 56/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2081 - rmse: 0.4561 - val_loss: 0.1792 - val_rmse: 0.4234\n",
            "Epoch 57/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2057 - rmse: 0.4535 - val_loss: 0.1808 - val_rmse: 0.4252\n",
            "Epoch 58/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2075 - rmse: 0.4555 - val_loss: 0.1770 - val_rmse: 0.4207\n",
            "Epoch 59/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2084 - rmse: 0.4565 - val_loss: 0.1758 - val_rmse: 0.4192\n",
            "Epoch 60/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2064 - rmse: 0.4543 - val_loss: 0.1706 - val_rmse: 0.4131\n",
            "Epoch 61/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2029 - rmse: 0.4505 - val_loss: 0.1688 - val_rmse: 0.4108\n",
            "Epoch 62/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2049 - rmse: 0.4527 - val_loss: 0.1760 - val_rmse: 0.4195\n",
            "Epoch 63/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2021 - rmse: 0.4496 - val_loss: 0.1689 - val_rmse: 0.4110\n",
            "Epoch 64/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2042 - rmse: 0.4519 - val_loss: 0.1750 - val_rmse: 0.4183\n",
            "Epoch 65/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2034 - rmse: 0.4510 - val_loss: 0.1685 - val_rmse: 0.4105\n",
            "Epoch 66/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.2016 - rmse: 0.4490 - val_loss: 0.1696 - val_rmse: 0.4118\n",
            "Epoch 67/100\n",
            "620/620 [==============================] - 15s 23ms/step - loss: 0.2005 - rmse: 0.4478 - val_loss: 0.1686 - val_rmse: 0.4106\n",
            "Epoch 68/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1998 - rmse: 0.4469 - val_loss: 0.1707 - val_rmse: 0.4131\n",
            "Epoch 69/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1980 - rmse: 0.4449 - val_loss: 0.1645 - val_rmse: 0.4056\n",
            "Epoch 70/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1955 - rmse: 0.4421 - val_loss: 0.1677 - val_rmse: 0.4096\n",
            "Epoch 71/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1961 - rmse: 0.4428 - val_loss: 0.1642 - val_rmse: 0.4052\n",
            "Epoch 72/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1945 - rmse: 0.4411 - val_loss: 0.1596 - val_rmse: 0.3994\n",
            "Epoch 73/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1935 - rmse: 0.4399 - val_loss: 0.1641 - val_rmse: 0.4052\n",
            "Epoch 74/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1958 - rmse: 0.4425 - val_loss: 0.1601 - val_rmse: 0.4002\n",
            "Epoch 75/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1928 - rmse: 0.4391 - val_loss: 0.1577 - val_rmse: 0.3971\n",
            "Epoch 76/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1897 - rmse: 0.4355 - val_loss: 0.1606 - val_rmse: 0.4008\n",
            "Epoch 77/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1889 - rmse: 0.4346 - val_loss: 0.1512 - val_rmse: 0.3888\n",
            "Epoch 78/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1882 - rmse: 0.4338 - val_loss: 0.1555 - val_rmse: 0.3944\n",
            "Epoch 79/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1861 - rmse: 0.4314 - val_loss: 0.1538 - val_rmse: 0.3921\n",
            "Epoch 80/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1858 - rmse: 0.4311 - val_loss: 0.1559 - val_rmse: 0.3948\n",
            "Epoch 81/100\n",
            "620/620 [==============================] - 15s 23ms/step - loss: 0.1837 - rmse: 0.4287 - val_loss: 0.1517 - val_rmse: 0.3895\n",
            "Epoch 82/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1829 - rmse: 0.4276 - val_loss: 0.1494 - val_rmse: 0.3865\n",
            "Epoch 83/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1814 - rmse: 0.4259 - val_loss: 0.1554 - val_rmse: 0.3942\n",
            "Epoch 84/100\n",
            "620/620 [==============================] - 15s 23ms/step - loss: 0.1807 - rmse: 0.4251 - val_loss: 0.1526 - val_rmse: 0.3906\n",
            "Epoch 85/100\n",
            "620/620 [==============================] - 15s 23ms/step - loss: 0.1797 - rmse: 0.4239 - val_loss: 0.1432 - val_rmse: 0.3785\n",
            "Epoch 86/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1779 - rmse: 0.4218 - val_loss: 0.1478 - val_rmse: 0.3845\n",
            "Epoch 87/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1801 - rmse: 0.4244 - val_loss: 0.1444 - val_rmse: 0.3800\n",
            "Epoch 88/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1753 - rmse: 0.4186 - val_loss: 0.1446 - val_rmse: 0.3802\n",
            "Epoch 89/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1727 - rmse: 0.4155 - val_loss: 0.1476 - val_rmse: 0.3841\n",
            "Epoch 90/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1743 - rmse: 0.4175 - val_loss: 0.1430 - val_rmse: 0.3782\n",
            "Epoch 91/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1695 - rmse: 0.4117 - val_loss: 0.1430 - val_rmse: 0.3782\n",
            "Epoch 92/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1694 - rmse: 0.4116 - val_loss: 0.1397 - val_rmse: 0.3738\n",
            "Epoch 93/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1663 - rmse: 0.4078 - val_loss: 0.1322 - val_rmse: 0.3636\n",
            "Epoch 94/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1655 - rmse: 0.4069 - val_loss: 0.1357 - val_rmse: 0.3684\n",
            "Epoch 95/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1652 - rmse: 0.4064 - val_loss: 0.1449 - val_rmse: 0.3807\n",
            "Epoch 96/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1621 - rmse: 0.4026 - val_loss: 0.1344 - val_rmse: 0.3666\n",
            "Epoch 97/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1595 - rmse: 0.3994 - val_loss: 0.1319 - val_rmse: 0.3632\n",
            "Epoch 98/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1609 - rmse: 0.4011 - val_loss: 0.1330 - val_rmse: 0.3647\n",
            "Epoch 99/100\n",
            "620/620 [==============================] - 15s 23ms/step - loss: 0.1592 - rmse: 0.3990 - val_loss: 0.1288 - val_rmse: 0.3589\n",
            "Epoch 100/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1564 - rmse: 0.3955 - val_loss: 0.1306 - val_rmse: 0.3614\n",
            "Score for fold 5: loss of 0.1305968165397644; rmse of 36.13818287849426%\n",
            "Epoch 1/100\n",
            "620/620 [==============================] - 16s 24ms/step - loss: 2.7361 - rmse: 1.6541 - val_loss: 0.3211 - val_rmse: 0.5667\n",
            "Epoch 2/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.4603 - rmse: 0.6784 - val_loss: 0.2724 - val_rmse: 0.5219\n",
            "Epoch 3/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.4223 - rmse: 0.6499 - val_loss: 0.2341 - val_rmse: 0.4839\n",
            "Epoch 4/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.3948 - rmse: 0.6284 - val_loss: 0.2934 - val_rmse: 0.5417\n",
            "Epoch 5/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.3808 - rmse: 0.6171 - val_loss: 0.2389 - val_rmse: 0.4888\n",
            "Epoch 6/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.3550 - rmse: 0.5958 - val_loss: 0.2836 - val_rmse: 0.5325\n",
            "Epoch 7/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.3054 - rmse: 0.5526 - val_loss: 0.2492 - val_rmse: 0.4992\n",
            "Epoch 8/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2998 - rmse: 0.5475 - val_loss: 0.3419 - val_rmse: 0.5848\n",
            "Epoch 9/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2782 - rmse: 0.5275 - val_loss: 0.2237 - val_rmse: 0.4730\n",
            "Epoch 10/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2672 - rmse: 0.5169 - val_loss: 0.2691 - val_rmse: 0.5188\n",
            "Epoch 11/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2649 - rmse: 0.5146 - val_loss: 0.2496 - val_rmse: 0.4996\n",
            "Epoch 12/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2621 - rmse: 0.5120 - val_loss: 0.2230 - val_rmse: 0.4722\n",
            "Epoch 13/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2571 - rmse: 0.5070 - val_loss: 0.2196 - val_rmse: 0.4687\n",
            "Epoch 14/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2565 - rmse: 0.5065 - val_loss: 0.2257 - val_rmse: 0.4750\n",
            "Epoch 15/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2499 - rmse: 0.4999 - val_loss: 0.2188 - val_rmse: 0.4677\n",
            "Epoch 16/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2531 - rmse: 0.5031 - val_loss: 0.2534 - val_rmse: 0.5034\n",
            "Epoch 17/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2506 - rmse: 0.5006 - val_loss: 0.2243 - val_rmse: 0.4736\n",
            "Epoch 18/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2497 - rmse: 0.4997 - val_loss: 0.3593 - val_rmse: 0.5994\n",
            "Epoch 19/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2431 - rmse: 0.4931 - val_loss: 0.2344 - val_rmse: 0.4841\n",
            "Epoch 20/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2391 - rmse: 0.4890 - val_loss: 0.2596 - val_rmse: 0.5095\n",
            "Epoch 21/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2384 - rmse: 0.4882 - val_loss: 0.2427 - val_rmse: 0.4927\n",
            "Epoch 22/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2403 - rmse: 0.4902 - val_loss: 0.2262 - val_rmse: 0.4756\n",
            "Epoch 23/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2399 - rmse: 0.4898 - val_loss: 0.2387 - val_rmse: 0.4886\n",
            "Epoch 24/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2388 - rmse: 0.4886 - val_loss: 0.2394 - val_rmse: 0.4892\n",
            "Epoch 25/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2364 - rmse: 0.4862 - val_loss: 0.2180 - val_rmse: 0.4669\n",
            "Epoch 26/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2381 - rmse: 0.4879 - val_loss: 0.2134 - val_rmse: 0.4620\n",
            "Epoch 27/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2375 - rmse: 0.4873 - val_loss: 0.2160 - val_rmse: 0.4647\n",
            "Epoch 28/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2355 - rmse: 0.4853 - val_loss: 0.2816 - val_rmse: 0.5306\n",
            "Epoch 29/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2286 - rmse: 0.4782 - val_loss: 0.2215 - val_rmse: 0.4707\n",
            "Epoch 30/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2325 - rmse: 0.4822 - val_loss: 0.2261 - val_rmse: 0.4755\n",
            "Epoch 31/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2316 - rmse: 0.4813 - val_loss: 0.2424 - val_rmse: 0.4923\n",
            "Epoch 32/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2298 - rmse: 0.4794 - val_loss: 0.2511 - val_rmse: 0.5011\n",
            "Epoch 33/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2262 - rmse: 0.4756 - val_loss: 0.2147 - val_rmse: 0.4633\n",
            "Epoch 34/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2296 - rmse: 0.4792 - val_loss: 0.2197 - val_rmse: 0.4687\n",
            "Epoch 35/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2265 - rmse: 0.4759 - val_loss: 0.2190 - val_rmse: 0.4679\n",
            "Epoch 36/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2286 - rmse: 0.4781 - val_loss: 0.2343 - val_rmse: 0.4840\n",
            "Epoch 37/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2220 - rmse: 0.4712 - val_loss: 0.2077 - val_rmse: 0.4557\n",
            "Epoch 38/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2238 - rmse: 0.4731 - val_loss: 0.2106 - val_rmse: 0.4589\n",
            "Epoch 39/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2212 - rmse: 0.4703 - val_loss: 0.2246 - val_rmse: 0.4739\n",
            "Epoch 40/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2223 - rmse: 0.4715 - val_loss: 0.2083 - val_rmse: 0.4564\n",
            "Epoch 41/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2193 - rmse: 0.4683 - val_loss: 0.2336 - val_rmse: 0.4833\n",
            "Epoch 42/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2211 - rmse: 0.4702 - val_loss: 0.2297 - val_rmse: 0.4792\n",
            "Epoch 43/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2183 - rmse: 0.4673 - val_loss: 0.2316 - val_rmse: 0.4812\n",
            "Epoch 44/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2181 - rmse: 0.4670 - val_loss: 0.2067 - val_rmse: 0.4546\n",
            "Epoch 45/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2179 - rmse: 0.4668 - val_loss: 0.2144 - val_rmse: 0.4631\n",
            "Epoch 46/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2191 - rmse: 0.4681 - val_loss: 0.2125 - val_rmse: 0.4610\n",
            "Epoch 47/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2188 - rmse: 0.4678 - val_loss: 0.2270 - val_rmse: 0.4765\n",
            "Epoch 48/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2172 - rmse: 0.4661 - val_loss: 0.2063 - val_rmse: 0.4542\n",
            "Epoch 49/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2156 - rmse: 0.4643 - val_loss: 0.2158 - val_rmse: 0.4645\n",
            "Epoch 50/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2144 - rmse: 0.4630 - val_loss: 0.2350 - val_rmse: 0.4847\n",
            "Epoch 51/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2154 - rmse: 0.4641 - val_loss: 0.2343 - val_rmse: 0.4840\n",
            "Epoch 52/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2127 - rmse: 0.4612 - val_loss: 0.2153 - val_rmse: 0.4640\n",
            "Epoch 53/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2148 - rmse: 0.4635 - val_loss: 0.2071 - val_rmse: 0.4551\n",
            "Epoch 54/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2112 - rmse: 0.4595 - val_loss: 0.2079 - val_rmse: 0.4559\n",
            "Epoch 55/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2129 - rmse: 0.4614 - val_loss: 0.2087 - val_rmse: 0.4569\n",
            "Epoch 56/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2098 - rmse: 0.4581 - val_loss: 0.2094 - val_rmse: 0.4576\n",
            "Epoch 57/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2078 - rmse: 0.4559 - val_loss: 0.2073 - val_rmse: 0.4553\n",
            "Epoch 58/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2107 - rmse: 0.4590 - val_loss: 0.2059 - val_rmse: 0.4538\n",
            "Epoch 59/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2090 - rmse: 0.4572 - val_loss: 0.2048 - val_rmse: 0.4525\n",
            "Epoch 60/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2076 - rmse: 0.4557 - val_loss: 0.2109 - val_rmse: 0.4593\n",
            "Epoch 61/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2082 - rmse: 0.4563 - val_loss: 0.2024 - val_rmse: 0.4499\n",
            "Epoch 62/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2063 - rmse: 0.4543 - val_loss: 0.1978 - val_rmse: 0.4447\n",
            "Epoch 63/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2058 - rmse: 0.4537 - val_loss: 0.2092 - val_rmse: 0.4574\n",
            "Epoch 64/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2064 - rmse: 0.4544 - val_loss: 0.2058 - val_rmse: 0.4536\n",
            "Epoch 65/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2024 - rmse: 0.4499 - val_loss: 0.2005 - val_rmse: 0.4478\n",
            "Epoch 66/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2044 - rmse: 0.4521 - val_loss: 0.2013 - val_rmse: 0.4486\n",
            "Epoch 67/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2041 - rmse: 0.4518 - val_loss: 0.1996 - val_rmse: 0.4467\n",
            "Epoch 68/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2025 - rmse: 0.4500 - val_loss: 0.2026 - val_rmse: 0.4501\n",
            "Epoch 69/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2011 - rmse: 0.4485 - val_loss: 0.2081 - val_rmse: 0.4562\n",
            "Epoch 70/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1998 - rmse: 0.4470 - val_loss: 0.1967 - val_rmse: 0.4435\n",
            "Epoch 71/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1982 - rmse: 0.4452 - val_loss: 0.2022 - val_rmse: 0.4497\n",
            "Epoch 72/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1981 - rmse: 0.4451 - val_loss: 0.2012 - val_rmse: 0.4485\n",
            "Epoch 73/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1992 - rmse: 0.4463 - val_loss: 0.2055 - val_rmse: 0.4533\n",
            "Epoch 74/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1968 - rmse: 0.4436 - val_loss: 0.2071 - val_rmse: 0.4551\n",
            "Epoch 75/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1954 - rmse: 0.4421 - val_loss: 0.1935 - val_rmse: 0.4399\n",
            "Epoch 76/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1946 - rmse: 0.4412 - val_loss: 0.1989 - val_rmse: 0.4460\n",
            "Epoch 77/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1939 - rmse: 0.4403 - val_loss: 0.2071 - val_rmse: 0.4551\n",
            "Epoch 78/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1941 - rmse: 0.4406 - val_loss: 0.1948 - val_rmse: 0.4414\n",
            "Epoch 79/100\n",
            "620/620 [==============================] - 15s 23ms/step - loss: 0.1896 - rmse: 0.4355 - val_loss: 0.1861 - val_rmse: 0.4314\n",
            "Epoch 80/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1905 - rmse: 0.4364 - val_loss: 0.1876 - val_rmse: 0.4331\n",
            "Epoch 81/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1890 - rmse: 0.4348 - val_loss: 0.1967 - val_rmse: 0.4435\n",
            "Epoch 82/100\n",
            "620/620 [==============================] - 15s 23ms/step - loss: 0.1886 - rmse: 0.4343 - val_loss: 0.1793 - val_rmse: 0.4234\n",
            "Epoch 83/100\n",
            "620/620 [==============================] - 14s 23ms/step - loss: 0.1871 - rmse: 0.4326 - val_loss: 0.1866 - val_rmse: 0.4319\n",
            "Epoch 84/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1842 - rmse: 0.4292 - val_loss: 0.1885 - val_rmse: 0.4342\n",
            "Epoch 85/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1824 - rmse: 0.4271 - val_loss: 0.1784 - val_rmse: 0.4224\n",
            "Epoch 86/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1824 - rmse: 0.4270 - val_loss: 0.1792 - val_rmse: 0.4233\n",
            "Epoch 87/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1784 - rmse: 0.4224 - val_loss: 0.1878 - val_rmse: 0.4334\n",
            "Epoch 88/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1820 - rmse: 0.4266 - val_loss: 0.1767 - val_rmse: 0.4203\n",
            "Epoch 89/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1808 - rmse: 0.4252 - val_loss: 0.1771 - val_rmse: 0.4208\n",
            "Epoch 90/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1772 - rmse: 0.4209 - val_loss: 0.1739 - val_rmse: 0.4170\n",
            "Epoch 91/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1750 - rmse: 0.4183 - val_loss: 0.1792 - val_rmse: 0.4234\n",
            "Epoch 92/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1754 - rmse: 0.4188 - val_loss: 0.1765 - val_rmse: 0.4201\n",
            "Epoch 93/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1724 - rmse: 0.4152 - val_loss: 0.1679 - val_rmse: 0.4098\n",
            "Epoch 94/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1716 - rmse: 0.4142 - val_loss: 0.1943 - val_rmse: 0.4408\n",
            "Epoch 95/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1708 - rmse: 0.4132 - val_loss: 0.1723 - val_rmse: 0.4150\n",
            "Epoch 96/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1689 - rmse: 0.4110 - val_loss: 0.1608 - val_rmse: 0.4010\n",
            "Epoch 97/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1664 - rmse: 0.4079 - val_loss: 0.1670 - val_rmse: 0.4087\n",
            "Epoch 98/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1675 - rmse: 0.4093 - val_loss: 0.1533 - val_rmse: 0.3916\n",
            "Epoch 99/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1645 - rmse: 0.4056 - val_loss: 0.1539 - val_rmse: 0.3923\n",
            "Epoch 100/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1640 - rmse: 0.4050 - val_loss: 0.1574 - val_rmse: 0.3967\n",
            "Score for fold 6: loss of 0.1573638767004013; rmse of 39.66911733150482%\n",
            "Epoch 1/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 1.9661 - rmse: 1.4022 - val_loss: 0.3402 - val_rmse: 0.5833\n",
            "Epoch 2/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.4363 - rmse: 0.6605 - val_loss: 0.2815 - val_rmse: 0.5305\n",
            "Epoch 3/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.4047 - rmse: 0.6362 - val_loss: 0.3006 - val_rmse: 0.5483\n",
            "Epoch 4/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.3899 - rmse: 0.6244 - val_loss: 0.3460 - val_rmse: 0.5883\n",
            "Epoch 5/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.3865 - rmse: 0.6217 - val_loss: 0.3096 - val_rmse: 0.5565\n",
            "Epoch 6/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.3364 - rmse: 0.5800 - val_loss: 0.2357 - val_rmse: 0.4855\n",
            "Epoch 7/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.3126 - rmse: 0.5591 - val_loss: 0.2386 - val_rmse: 0.4885\n",
            "Epoch 8/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2864 - rmse: 0.5352 - val_loss: 0.2788 - val_rmse: 0.5280\n",
            "Epoch 9/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2775 - rmse: 0.5267 - val_loss: 0.2329 - val_rmse: 0.4826\n",
            "Epoch 10/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2618 - rmse: 0.5117 - val_loss: 0.3516 - val_rmse: 0.5929\n",
            "Epoch 11/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2522 - rmse: 0.5022 - val_loss: 0.2873 - val_rmse: 0.5360\n",
            "Epoch 12/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2534 - rmse: 0.5034 - val_loss: 0.2389 - val_rmse: 0.4888\n",
            "Epoch 13/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2492 - rmse: 0.4992 - val_loss: 0.2327 - val_rmse: 0.4823\n",
            "Epoch 14/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2533 - rmse: 0.5033 - val_loss: 0.2538 - val_rmse: 0.5038\n",
            "Epoch 15/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2431 - rmse: 0.4931 - val_loss: 0.2322 - val_rmse: 0.4818\n",
            "Epoch 16/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2400 - rmse: 0.4899 - val_loss: 0.2318 - val_rmse: 0.4814\n",
            "Epoch 17/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2369 - rmse: 0.4867 - val_loss: 0.2481 - val_rmse: 0.4981\n",
            "Epoch 18/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2389 - rmse: 0.4888 - val_loss: 0.2522 - val_rmse: 0.5021\n",
            "Epoch 19/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2373 - rmse: 0.4872 - val_loss: 0.2589 - val_rmse: 0.5089\n",
            "Epoch 20/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2357 - rmse: 0.4855 - val_loss: 0.2510 - val_rmse: 0.5010\n",
            "Epoch 21/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2341 - rmse: 0.4839 - val_loss: 0.2366 - val_rmse: 0.4864\n",
            "Epoch 22/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2398 - rmse: 0.4897 - val_loss: 0.2683 - val_rmse: 0.5180\n",
            "Epoch 23/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2354 - rmse: 0.4852 - val_loss: 0.2504 - val_rmse: 0.5004\n",
            "Epoch 24/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2371 - rmse: 0.4869 - val_loss: 0.2425 - val_rmse: 0.4925\n",
            "Epoch 25/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2301 - rmse: 0.4797 - val_loss: 0.2285 - val_rmse: 0.4780\n",
            "Epoch 26/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2312 - rmse: 0.4809 - val_loss: 0.2246 - val_rmse: 0.4739\n",
            "Epoch 27/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2299 - rmse: 0.4795 - val_loss: 0.2391 - val_rmse: 0.4890\n",
            "Epoch 28/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2282 - rmse: 0.4777 - val_loss: 0.2376 - val_rmse: 0.4874\n",
            "Epoch 29/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2291 - rmse: 0.4786 - val_loss: 0.2204 - val_rmse: 0.4694\n",
            "Epoch 30/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2297 - rmse: 0.4793 - val_loss: 0.2307 - val_rmse: 0.4803\n",
            "Epoch 31/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2259 - rmse: 0.4753 - val_loss: 0.2241 - val_rmse: 0.4734\n",
            "Epoch 32/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2246 - rmse: 0.4739 - val_loss: 0.2213 - val_rmse: 0.4704\n",
            "Epoch 33/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2236 - rmse: 0.4729 - val_loss: 0.2262 - val_rmse: 0.4756\n",
            "Epoch 34/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2244 - rmse: 0.4738 - val_loss: 0.2456 - val_rmse: 0.4956\n",
            "Epoch 35/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2255 - rmse: 0.4749 - val_loss: 0.2383 - val_rmse: 0.4882\n",
            "Epoch 36/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2231 - rmse: 0.4723 - val_loss: 0.2265 - val_rmse: 0.4759\n",
            "Epoch 37/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2212 - rmse: 0.4703 - val_loss: 0.2295 - val_rmse: 0.4790\n",
            "Epoch 38/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2208 - rmse: 0.4699 - val_loss: 0.2205 - val_rmse: 0.4696\n",
            "Epoch 39/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2204 - rmse: 0.4695 - val_loss: 0.2169 - val_rmse: 0.4657\n",
            "Epoch 40/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2176 - rmse: 0.4664 - val_loss: 0.2152 - val_rmse: 0.4639\n",
            "Epoch 41/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2200 - rmse: 0.4691 - val_loss: 0.2501 - val_rmse: 0.5001\n",
            "Epoch 42/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2148 - rmse: 0.4635 - val_loss: 0.2138 - val_rmse: 0.4624\n",
            "Epoch 43/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2197 - rmse: 0.4687 - val_loss: 0.2162 - val_rmse: 0.4650\n",
            "Epoch 44/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2163 - rmse: 0.4651 - val_loss: 0.2241 - val_rmse: 0.4734\n",
            "Epoch 45/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2192 - rmse: 0.4681 - val_loss: 0.2161 - val_rmse: 0.4649\n",
            "Epoch 46/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2178 - rmse: 0.4667 - val_loss: 0.2208 - val_rmse: 0.4699\n",
            "Epoch 47/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2167 - rmse: 0.4655 - val_loss: 0.2147 - val_rmse: 0.4634\n",
            "Epoch 48/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2156 - rmse: 0.4644 - val_loss: 0.2383 - val_rmse: 0.4882\n",
            "Epoch 49/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2162 - rmse: 0.4649 - val_loss: 0.2160 - val_rmse: 0.4648\n",
            "Epoch 50/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2125 - rmse: 0.4610 - val_loss: 0.2129 - val_rmse: 0.4614\n",
            "Epoch 51/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2130 - rmse: 0.4615 - val_loss: 0.2128 - val_rmse: 0.4613\n",
            "Epoch 52/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2115 - rmse: 0.4599 - val_loss: 0.2080 - val_rmse: 0.4561\n",
            "Epoch 53/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2127 - rmse: 0.4612 - val_loss: 0.2208 - val_rmse: 0.4698\n",
            "Epoch 54/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2124 - rmse: 0.4609 - val_loss: 0.2083 - val_rmse: 0.4564\n",
            "Epoch 55/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2092 - rmse: 0.4574 - val_loss: 0.2144 - val_rmse: 0.4630\n",
            "Epoch 56/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2101 - rmse: 0.4584 - val_loss: 0.2095 - val_rmse: 0.4577\n",
            "Epoch 57/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2077 - rmse: 0.4557 - val_loss: 0.2095 - val_rmse: 0.4578\n",
            "Epoch 58/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2093 - rmse: 0.4575 - val_loss: 0.2032 - val_rmse: 0.4507\n",
            "Epoch 59/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2086 - rmse: 0.4568 - val_loss: 0.2235 - val_rmse: 0.4727\n",
            "Epoch 60/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2068 - rmse: 0.4547 - val_loss: 0.2115 - val_rmse: 0.4599\n",
            "Epoch 61/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2055 - rmse: 0.4534 - val_loss: 0.2052 - val_rmse: 0.4529\n",
            "Epoch 62/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2064 - rmse: 0.4543 - val_loss: 0.2023 - val_rmse: 0.4498\n",
            "Epoch 63/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2039 - rmse: 0.4516 - val_loss: 0.2025 - val_rmse: 0.4500\n",
            "Epoch 64/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2034 - rmse: 0.4510 - val_loss: 0.2033 - val_rmse: 0.4509\n",
            "Epoch 65/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2049 - rmse: 0.4527 - val_loss: 0.2091 - val_rmse: 0.4573\n",
            "Epoch 66/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2033 - rmse: 0.4508 - val_loss: 0.1981 - val_rmse: 0.4451\n",
            "Epoch 67/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2018 - rmse: 0.4492 - val_loss: 0.2056 - val_rmse: 0.4534\n",
            "Epoch 68/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2014 - rmse: 0.4488 - val_loss: 0.1994 - val_rmse: 0.4466\n",
            "Epoch 69/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1992 - rmse: 0.4463 - val_loss: 0.2064 - val_rmse: 0.4543\n",
            "Epoch 70/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1984 - rmse: 0.4454 - val_loss: 0.1881 - val_rmse: 0.4337\n",
            "Epoch 71/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1978 - rmse: 0.4448 - val_loss: 0.1993 - val_rmse: 0.4464\n",
            "Epoch 72/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1952 - rmse: 0.4418 - val_loss: 0.2053 - val_rmse: 0.4531\n",
            "Epoch 73/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1974 - rmse: 0.4443 - val_loss: 0.1860 - val_rmse: 0.4313\n",
            "Epoch 74/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1950 - rmse: 0.4416 - val_loss: 0.1838 - val_rmse: 0.4287\n",
            "Epoch 75/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1955 - rmse: 0.4421 - val_loss: 0.1856 - val_rmse: 0.4309\n",
            "Epoch 76/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1927 - rmse: 0.4390 - val_loss: 0.1855 - val_rmse: 0.4307\n",
            "Epoch 77/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1943 - rmse: 0.4408 - val_loss: 0.1859 - val_rmse: 0.4312\n",
            "Epoch 78/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1906 - rmse: 0.4365 - val_loss: 0.1768 - val_rmse: 0.4205\n",
            "Epoch 79/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1916 - rmse: 0.4377 - val_loss: 0.1904 - val_rmse: 0.4364\n",
            "Epoch 80/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1877 - rmse: 0.4333 - val_loss: 0.1932 - val_rmse: 0.4396\n",
            "Epoch 81/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1876 - rmse: 0.4332 - val_loss: 0.1756 - val_rmse: 0.4190\n",
            "Epoch 82/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1867 - rmse: 0.4320 - val_loss: 0.1781 - val_rmse: 0.4221\n",
            "Epoch 83/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1854 - rmse: 0.4306 - val_loss: 0.1703 - val_rmse: 0.4127\n",
            "Epoch 84/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1868 - rmse: 0.4322 - val_loss: 0.1719 - val_rmse: 0.4146\n",
            "Epoch 85/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1829 - rmse: 0.4276 - val_loss: 0.1749 - val_rmse: 0.4182\n",
            "Epoch 86/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1795 - rmse: 0.4236 - val_loss: 0.1802 - val_rmse: 0.4245\n",
            "Epoch 87/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1807 - rmse: 0.4250 - val_loss: 0.1737 - val_rmse: 0.4168\n",
            "Epoch 88/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1808 - rmse: 0.4252 - val_loss: 0.1648 - val_rmse: 0.4059\n",
            "Epoch 89/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1781 - rmse: 0.4220 - val_loss: 0.1840 - val_rmse: 0.4289\n",
            "Epoch 90/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1769 - rmse: 0.4206 - val_loss: 0.1674 - val_rmse: 0.4092\n",
            "Epoch 91/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1745 - rmse: 0.4177 - val_loss: 0.1666 - val_rmse: 0.4081\n",
            "Epoch 92/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1728 - rmse: 0.4157 - val_loss: 0.1607 - val_rmse: 0.4009\n",
            "Epoch 93/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.1713 - rmse: 0.4139 - val_loss: 0.1691 - val_rmse: 0.4112\n",
            "Epoch 94/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1715 - rmse: 0.4142 - val_loss: 0.1550 - val_rmse: 0.3937\n",
            "Epoch 95/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1690 - rmse: 0.4111 - val_loss: 0.1565 - val_rmse: 0.3956\n",
            "Epoch 96/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1661 - rmse: 0.4075 - val_loss: 0.1657 - val_rmse: 0.4070\n",
            "Epoch 97/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1660 - rmse: 0.4074 - val_loss: 0.1531 - val_rmse: 0.3913\n",
            "Epoch 98/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1643 - rmse: 0.4054 - val_loss: 0.1553 - val_rmse: 0.3941\n",
            "Epoch 99/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1617 - rmse: 0.4021 - val_loss: 0.1462 - val_rmse: 0.3824\n",
            "Epoch 100/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1607 - rmse: 0.4009 - val_loss: 0.1510 - val_rmse: 0.3886\n",
            "Score for fold 7: loss of 0.15097413957118988; rmse of 38.85539174079895%\n",
            "Epoch 1/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 2.5448 - rmse: 1.5953 - val_loss: 0.2612 - val_rmse: 0.5111\n",
            "Epoch 2/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.4397 - rmse: 0.6631 - val_loss: 0.2433 - val_rmse: 0.4933\n",
            "Epoch 3/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.4218 - rmse: 0.6495 - val_loss: 0.2170 - val_rmse: 0.4659\n",
            "Epoch 4/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.4087 - rmse: 0.6393 - val_loss: 0.2232 - val_rmse: 0.4724\n",
            "Epoch 5/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.3774 - rmse: 0.6143 - val_loss: 0.2339 - val_rmse: 0.4836\n",
            "Epoch 6/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.3549 - rmse: 0.5958 - val_loss: 0.2608 - val_rmse: 0.5106\n",
            "Epoch 7/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.3157 - rmse: 0.5619 - val_loss: 0.2526 - val_rmse: 0.5026\n",
            "Epoch 8/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2947 - rmse: 0.5429 - val_loss: 0.2049 - val_rmse: 0.4527\n",
            "Epoch 9/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2760 - rmse: 0.5253 - val_loss: 0.2220 - val_rmse: 0.4711\n",
            "Epoch 10/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2712 - rmse: 0.5208 - val_loss: 0.2394 - val_rmse: 0.4893\n",
            "Epoch 11/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2637 - rmse: 0.5135 - val_loss: 0.2803 - val_rmse: 0.5295\n",
            "Epoch 12/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2587 - rmse: 0.5086 - val_loss: 0.2166 - val_rmse: 0.4654\n",
            "Epoch 13/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2582 - rmse: 0.5081 - val_loss: 0.2694 - val_rmse: 0.5191\n",
            "Epoch 14/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2471 - rmse: 0.4971 - val_loss: 0.2181 - val_rmse: 0.4670\n",
            "Epoch 15/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2459 - rmse: 0.4959 - val_loss: 0.2092 - val_rmse: 0.4574\n",
            "Epoch 16/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2492 - rmse: 0.4992 - val_loss: 0.2213 - val_rmse: 0.4705\n",
            "Epoch 17/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2479 - rmse: 0.4979 - val_loss: 0.1980 - val_rmse: 0.4450\n",
            "Epoch 18/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2432 - rmse: 0.4932 - val_loss: 0.2027 - val_rmse: 0.4502\n",
            "Epoch 19/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2426 - rmse: 0.4925 - val_loss: 0.2041 - val_rmse: 0.4518\n",
            "Epoch 20/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2407 - rmse: 0.4907 - val_loss: 0.2058 - val_rmse: 0.4536\n",
            "Epoch 21/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2351 - rmse: 0.4849 - val_loss: 0.1975 - val_rmse: 0.4444\n",
            "Epoch 22/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2370 - rmse: 0.4868 - val_loss: 0.2073 - val_rmse: 0.4553\n",
            "Epoch 23/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2406 - rmse: 0.4905 - val_loss: 0.2078 - val_rmse: 0.4559\n",
            "Epoch 24/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2351 - rmse: 0.4849 - val_loss: 0.2235 - val_rmse: 0.4727\n",
            "Epoch 25/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2349 - rmse: 0.4847 - val_loss: 0.1960 - val_rmse: 0.4427\n",
            "Epoch 26/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2365 - rmse: 0.4863 - val_loss: 0.2177 - val_rmse: 0.4666\n",
            "Epoch 27/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2316 - rmse: 0.4813 - val_loss: 0.2508 - val_rmse: 0.5008\n",
            "Epoch 28/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2318 - rmse: 0.4814 - val_loss: 0.2141 - val_rmse: 0.4627\n",
            "Epoch 29/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2302 - rmse: 0.4798 - val_loss: 0.2014 - val_rmse: 0.4487\n",
            "Epoch 30/100\n",
            "620/620 [==============================] - 18s 30ms/step - loss: 0.2278 - rmse: 0.4773 - val_loss: 0.2040 - val_rmse: 0.4517\n",
            "Epoch 31/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2285 - rmse: 0.4780 - val_loss: 0.1984 - val_rmse: 0.4454\n",
            "Epoch 32/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2283 - rmse: 0.4778 - val_loss: 0.1982 - val_rmse: 0.4452\n",
            "Epoch 33/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2290 - rmse: 0.4785 - val_loss: 0.1969 - val_rmse: 0.4438\n",
            "Epoch 34/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2254 - rmse: 0.4748 - val_loss: 0.2002 - val_rmse: 0.4474\n",
            "Epoch 35/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2237 - rmse: 0.4730 - val_loss: 0.1954 - val_rmse: 0.4421\n",
            "Epoch 36/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.2253 - rmse: 0.4746 - val_loss: 0.2110 - val_rmse: 0.4593\n",
            "Epoch 37/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2237 - rmse: 0.4730 - val_loss: 0.1913 - val_rmse: 0.4374\n",
            "Epoch 38/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2248 - rmse: 0.4742 - val_loss: 0.1938 - val_rmse: 0.4403\n",
            "Epoch 39/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2237 - rmse: 0.4730 - val_loss: 0.1976 - val_rmse: 0.4445\n",
            "Epoch 40/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2235 - rmse: 0.4728 - val_loss: 0.2135 - val_rmse: 0.4621\n",
            "Epoch 41/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2208 - rmse: 0.4699 - val_loss: 0.1928 - val_rmse: 0.4391\n",
            "Epoch 42/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2204 - rmse: 0.4695 - val_loss: 0.2008 - val_rmse: 0.4481\n",
            "Epoch 43/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2172 - rmse: 0.4661 - val_loss: 0.2048 - val_rmse: 0.4525\n",
            "Epoch 44/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2193 - rmse: 0.4683 - val_loss: 0.1920 - val_rmse: 0.4381\n",
            "Epoch 45/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2174 - rmse: 0.4663 - val_loss: 0.2152 - val_rmse: 0.4639\n",
            "Epoch 46/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2165 - rmse: 0.4653 - val_loss: 0.1999 - val_rmse: 0.4471\n",
            "Epoch 47/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2174 - rmse: 0.4662 - val_loss: 0.1895 - val_rmse: 0.4353\n",
            "Epoch 48/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2161 - rmse: 0.4649 - val_loss: 0.1904 - val_rmse: 0.4363\n",
            "Epoch 49/100\n",
            "620/620 [==============================] - 15s 24ms/step - loss: 0.2151 - rmse: 0.4638 - val_loss: 0.1892 - val_rmse: 0.4350\n",
            "Epoch 50/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2147 - rmse: 0.4633 - val_loss: 0.1890 - val_rmse: 0.4347\n",
            "Epoch 51/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2149 - rmse: 0.4636 - val_loss: 0.1847 - val_rmse: 0.4298\n",
            "Epoch 52/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2134 - rmse: 0.4619 - val_loss: 0.1867 - val_rmse: 0.4320\n",
            "Epoch 53/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2129 - rmse: 0.4614 - val_loss: 0.1965 - val_rmse: 0.4433\n",
            "Epoch 54/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2131 - rmse: 0.4616 - val_loss: 0.1911 - val_rmse: 0.4371\n",
            "Epoch 55/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2124 - rmse: 0.4608 - val_loss: 0.1851 - val_rmse: 0.4302\n",
            "Epoch 56/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2106 - rmse: 0.4589 - val_loss: 0.1865 - val_rmse: 0.4319\n",
            "Epoch 57/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2102 - rmse: 0.4584 - val_loss: 0.1853 - val_rmse: 0.4305\n",
            "Epoch 58/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2095 - rmse: 0.4577 - val_loss: 0.1881 - val_rmse: 0.4337\n",
            "Epoch 59/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2098 - rmse: 0.4580 - val_loss: 0.1822 - val_rmse: 0.4268\n",
            "Epoch 60/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2087 - rmse: 0.4569 - val_loss: 0.1844 - val_rmse: 0.4294\n",
            "Epoch 61/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2077 - rmse: 0.4557 - val_loss: 0.1844 - val_rmse: 0.4295\n",
            "Epoch 62/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2040 - rmse: 0.4516 - val_loss: 0.1889 - val_rmse: 0.4347\n",
            "Epoch 63/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2075 - rmse: 0.4555 - val_loss: 0.1775 - val_rmse: 0.4213\n",
            "Epoch 64/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2033 - rmse: 0.4509 - val_loss: 0.1832 - val_rmse: 0.4280\n",
            "Epoch 65/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2022 - rmse: 0.4497 - val_loss: 0.1827 - val_rmse: 0.4274\n",
            "Epoch 66/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2034 - rmse: 0.4510 - val_loss: 0.1837 - val_rmse: 0.4286\n",
            "Epoch 67/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2016 - rmse: 0.4490 - val_loss: 0.1793 - val_rmse: 0.4235\n",
            "Epoch 68/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2030 - rmse: 0.4506 - val_loss: 0.1850 - val_rmse: 0.4302\n",
            "Epoch 69/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1976 - rmse: 0.4445 - val_loss: 0.1970 - val_rmse: 0.4439\n",
            "Epoch 70/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2010 - rmse: 0.4483 - val_loss: 0.1767 - val_rmse: 0.4204\n",
            "Epoch 71/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1993 - rmse: 0.4464 - val_loss: 0.1884 - val_rmse: 0.4340\n",
            "Epoch 72/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1957 - rmse: 0.4424 - val_loss: 0.1811 - val_rmse: 0.4256\n",
            "Epoch 73/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1963 - rmse: 0.4430 - val_loss: 0.1782 - val_rmse: 0.4221\n",
            "Epoch 74/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1956 - rmse: 0.4422 - val_loss: 0.1752 - val_rmse: 0.4185\n",
            "Epoch 75/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1950 - rmse: 0.4415 - val_loss: 0.1675 - val_rmse: 0.4093\n",
            "Epoch 76/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1946 - rmse: 0.4411 - val_loss: 0.1654 - val_rmse: 0.4066\n",
            "Epoch 77/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1934 - rmse: 0.4398 - val_loss: 0.1690 - val_rmse: 0.4111\n",
            "Epoch 78/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1915 - rmse: 0.4376 - val_loss: 0.1672 - val_rmse: 0.4089\n",
            "Epoch 79/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1931 - rmse: 0.4394 - val_loss: 0.1646 - val_rmse: 0.4058\n",
            "Epoch 80/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1880 - rmse: 0.4336 - val_loss: 0.1664 - val_rmse: 0.4080\n",
            "Epoch 81/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1898 - rmse: 0.4357 - val_loss: 0.1692 - val_rmse: 0.4113\n",
            "Epoch 82/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1886 - rmse: 0.4343 - val_loss: 0.1640 - val_rmse: 0.4049\n",
            "Epoch 83/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1851 - rmse: 0.4303 - val_loss: 0.1669 - val_rmse: 0.4086\n",
            "Epoch 84/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1872 - rmse: 0.4327 - val_loss: 0.1637 - val_rmse: 0.4046\n",
            "Epoch 85/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1844 - rmse: 0.4294 - val_loss: 0.1599 - val_rmse: 0.3999\n",
            "Epoch 86/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1841 - rmse: 0.4290 - val_loss: 0.1650 - val_rmse: 0.4062\n",
            "Epoch 87/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1801 - rmse: 0.4244 - val_loss: 0.1660 - val_rmse: 0.4075\n",
            "Epoch 88/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1805 - rmse: 0.4249 - val_loss: 0.1540 - val_rmse: 0.3924\n",
            "Epoch 89/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1795 - rmse: 0.4237 - val_loss: 0.1545 - val_rmse: 0.3931\n",
            "Epoch 90/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1781 - rmse: 0.4221 - val_loss: 0.1575 - val_rmse: 0.3968\n",
            "Epoch 91/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1761 - rmse: 0.4197 - val_loss: 0.1595 - val_rmse: 0.3994\n",
            "Epoch 92/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1731 - rmse: 0.4161 - val_loss: 0.1520 - val_rmse: 0.3899\n",
            "Epoch 93/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.1753 - rmse: 0.4187 - val_loss: 0.1520 - val_rmse: 0.3899\n",
            "Epoch 94/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1738 - rmse: 0.4169 - val_loss: 0.1465 - val_rmse: 0.3828\n",
            "Epoch 95/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1713 - rmse: 0.4139 - val_loss: 0.1455 - val_rmse: 0.3814\n",
            "Epoch 96/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1694 - rmse: 0.4116 - val_loss: 0.1500 - val_rmse: 0.3874\n",
            "Epoch 97/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1687 - rmse: 0.4108 - val_loss: 0.1469 - val_rmse: 0.3833\n",
            "Epoch 98/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1683 - rmse: 0.4102 - val_loss: 0.1490 - val_rmse: 0.3860\n",
            "Epoch 99/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1676 - rmse: 0.4093 - val_loss: 0.1489 - val_rmse: 0.3859\n",
            "Epoch 100/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1666 - rmse: 0.4082 - val_loss: 0.1461 - val_rmse: 0.3822\n",
            "Score for fold 8: loss of 0.14605951309204102; rmse of 38.217732310295105%\n",
            "Epoch 1/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 2.2187 - rmse: 1.4895 - val_loss: 0.3210 - val_rmse: 0.5666\n",
            "Epoch 2/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.4891 - rmse: 0.6993 - val_loss: 0.2573 - val_rmse: 0.5072\n",
            "Epoch 3/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.4368 - rmse: 0.6609 - val_loss: 0.2704 - val_rmse: 0.5200\n",
            "Epoch 4/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.4181 - rmse: 0.6466 - val_loss: 0.2271 - val_rmse: 0.4766\n",
            "Epoch 5/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.4160 - rmse: 0.6450 - val_loss: 0.2374 - val_rmse: 0.4872\n",
            "Epoch 6/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.3814 - rmse: 0.6176 - val_loss: 0.2957 - val_rmse: 0.5438\n",
            "Epoch 7/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.3493 - rmse: 0.5910 - val_loss: 0.2564 - val_rmse: 0.5063\n",
            "Epoch 8/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.3064 - rmse: 0.5535 - val_loss: 0.2317 - val_rmse: 0.4814\n",
            "Epoch 9/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2782 - rmse: 0.5274 - val_loss: 0.2546 - val_rmse: 0.5046\n",
            "Epoch 10/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2724 - rmse: 0.5219 - val_loss: 0.2056 - val_rmse: 0.4534\n",
            "Epoch 11/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2613 - rmse: 0.5111 - val_loss: 0.2066 - val_rmse: 0.4546\n",
            "Epoch 12/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2552 - rmse: 0.5052 - val_loss: 0.2062 - val_rmse: 0.4541\n",
            "Epoch 13/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2503 - rmse: 0.5003 - val_loss: 0.2472 - val_rmse: 0.4972\n",
            "Epoch 14/100\n",
            "620/620 [==============================] - 15s 25ms/step - loss: 0.2548 - rmse: 0.5048 - val_loss: 0.1999 - val_rmse: 0.4471\n",
            "Epoch 15/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2446 - rmse: 0.4946 - val_loss: 0.2068 - val_rmse: 0.4548\n",
            "Epoch 16/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2438 - rmse: 0.4938 - val_loss: 0.2204 - val_rmse: 0.4695\n",
            "Epoch 17/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2460 - rmse: 0.4960 - val_loss: 0.2289 - val_rmse: 0.4784\n",
            "Epoch 18/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2411 - rmse: 0.4910 - val_loss: 0.2136 - val_rmse: 0.4622\n",
            "Epoch 19/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2443 - rmse: 0.4943 - val_loss: 0.2086 - val_rmse: 0.4568\n",
            "Epoch 20/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2416 - rmse: 0.4915 - val_loss: 0.2107 - val_rmse: 0.4590\n",
            "Epoch 21/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2409 - rmse: 0.4909 - val_loss: 0.2098 - val_rmse: 0.4580\n",
            "Epoch 22/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2374 - rmse: 0.4873 - val_loss: 0.2112 - val_rmse: 0.4596\n",
            "Epoch 23/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2375 - rmse: 0.4873 - val_loss: 0.2359 - val_rmse: 0.4857\n",
            "Epoch 24/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2407 - rmse: 0.4906 - val_loss: 0.2043 - val_rmse: 0.4520\n",
            "Epoch 25/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2331 - rmse: 0.4828 - val_loss: 0.2103 - val_rmse: 0.4586\n",
            "Epoch 26/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2331 - rmse: 0.4828 - val_loss: 0.1978 - val_rmse: 0.4447\n",
            "Epoch 27/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2322 - rmse: 0.4818 - val_loss: 0.1973 - val_rmse: 0.4442\n",
            "Epoch 28/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2311 - rmse: 0.4808 - val_loss: 0.1979 - val_rmse: 0.4448\n",
            "Epoch 29/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2312 - rmse: 0.4808 - val_loss: 0.2141 - val_rmse: 0.4627\n",
            "Epoch 30/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2283 - rmse: 0.4778 - val_loss: 0.2026 - val_rmse: 0.4501\n",
            "Epoch 31/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2284 - rmse: 0.4780 - val_loss: 0.2034 - val_rmse: 0.4510\n",
            "Epoch 32/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2289 - rmse: 0.4784 - val_loss: 0.2045 - val_rmse: 0.4522\n",
            "Epoch 33/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2294 - rmse: 0.4790 - val_loss: 0.1978 - val_rmse: 0.4448\n",
            "Epoch 34/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2272 - rmse: 0.4766 - val_loss: 0.2059 - val_rmse: 0.4537\n",
            "Epoch 35/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2254 - rmse: 0.4747 - val_loss: 0.2027 - val_rmse: 0.4502\n",
            "Epoch 36/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2226 - rmse: 0.4718 - val_loss: 0.1929 - val_rmse: 0.4392\n",
            "Epoch 37/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2214 - rmse: 0.4705 - val_loss: 0.2003 - val_rmse: 0.4475\n",
            "Epoch 38/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2215 - rmse: 0.4707 - val_loss: 0.1955 - val_rmse: 0.4421\n",
            "Epoch 39/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2232 - rmse: 0.4724 - val_loss: 0.1976 - val_rmse: 0.4445\n",
            "Epoch 40/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2219 - rmse: 0.4711 - val_loss: 0.1934 - val_rmse: 0.4398\n",
            "Epoch 41/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2211 - rmse: 0.4703 - val_loss: 0.2007 - val_rmse: 0.4479\n",
            "Epoch 42/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2185 - rmse: 0.4674 - val_loss: 0.1967 - val_rmse: 0.4435\n",
            "Epoch 43/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2200 - rmse: 0.4691 - val_loss: 0.1914 - val_rmse: 0.4375\n",
            "Epoch 44/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2174 - rmse: 0.4662 - val_loss: 0.2035 - val_rmse: 0.4511\n",
            "Epoch 45/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2210 - rmse: 0.4701 - val_loss: 0.1997 - val_rmse: 0.4469\n",
            "Epoch 46/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2164 - rmse: 0.4652 - val_loss: 0.1911 - val_rmse: 0.4371\n",
            "Epoch 47/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2179 - rmse: 0.4668 - val_loss: 0.2377 - val_rmse: 0.4875\n",
            "Epoch 48/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2143 - rmse: 0.4629 - val_loss: 0.1892 - val_rmse: 0.4349\n",
            "Epoch 49/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2134 - rmse: 0.4619 - val_loss: 0.2005 - val_rmse: 0.4477\n",
            "Epoch 50/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2143 - rmse: 0.4629 - val_loss: 0.1951 - val_rmse: 0.4418\n",
            "Epoch 51/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2131 - rmse: 0.4616 - val_loss: 0.2011 - val_rmse: 0.4485\n",
            "Epoch 52/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2116 - rmse: 0.4600 - val_loss: 0.1930 - val_rmse: 0.4393\n",
            "Epoch 53/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2130 - rmse: 0.4615 - val_loss: 0.1895 - val_rmse: 0.4353\n",
            "Epoch 54/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2134 - rmse: 0.4620 - val_loss: 0.1977 - val_rmse: 0.4447\n",
            "Epoch 55/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2109 - rmse: 0.4592 - val_loss: 0.1898 - val_rmse: 0.4356\n",
            "Epoch 56/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2096 - rmse: 0.4578 - val_loss: 0.2063 - val_rmse: 0.4543\n",
            "Epoch 57/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2109 - rmse: 0.4592 - val_loss: 0.1971 - val_rmse: 0.4440\n",
            "Epoch 58/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2085 - rmse: 0.4566 - val_loss: 0.1926 - val_rmse: 0.4389\n",
            "Epoch 59/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2076 - rmse: 0.4556 - val_loss: 0.1850 - val_rmse: 0.4301\n",
            "Epoch 60/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2085 - rmse: 0.4567 - val_loss: 0.1803 - val_rmse: 0.4246\n",
            "Epoch 61/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2057 - rmse: 0.4535 - val_loss: 0.1904 - val_rmse: 0.4363\n",
            "Epoch 62/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2046 - rmse: 0.4523 - val_loss: 0.1926 - val_rmse: 0.4389\n",
            "Epoch 63/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2037 - rmse: 0.4514 - val_loss: 0.1844 - val_rmse: 0.4295\n",
            "Epoch 64/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2049 - rmse: 0.4526 - val_loss: 0.1844 - val_rmse: 0.4294\n",
            "Epoch 65/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2066 - rmse: 0.4545 - val_loss: 0.1835 - val_rmse: 0.4283\n",
            "Epoch 66/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2049 - rmse: 0.4527 - val_loss: 0.1857 - val_rmse: 0.4309\n",
            "Epoch 67/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2011 - rmse: 0.4485 - val_loss: 0.1862 - val_rmse: 0.4315\n",
            "Epoch 68/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2013 - rmse: 0.4487 - val_loss: 0.1731 - val_rmse: 0.4161\n",
            "Epoch 69/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1995 - rmse: 0.4466 - val_loss: 0.1872 - val_rmse: 0.4326\n",
            "Epoch 70/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.2004 - rmse: 0.4476 - val_loss: 0.1766 - val_rmse: 0.4202\n",
            "Epoch 71/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1977 - rmse: 0.4446 - val_loss: 0.1781 - val_rmse: 0.4220\n",
            "Epoch 72/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1972 - rmse: 0.4440 - val_loss: 0.1801 - val_rmse: 0.4244\n",
            "Epoch 73/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1974 - rmse: 0.4443 - val_loss: 0.1815 - val_rmse: 0.4260\n",
            "Epoch 74/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1947 - rmse: 0.4413 - val_loss: 0.1781 - val_rmse: 0.4220\n",
            "Epoch 75/100\n",
            "620/620 [==============================] - 16s 25ms/step - loss: 0.1958 - rmse: 0.4425 - val_loss: 0.1783 - val_rmse: 0.4222\n",
            "Epoch 76/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1933 - rmse: 0.4397 - val_loss: 0.1745 - val_rmse: 0.4177\n",
            "Epoch 77/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1943 - rmse: 0.4408 - val_loss: 0.1775 - val_rmse: 0.4213\n",
            "Epoch 78/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1918 - rmse: 0.4379 - val_loss: 0.1761 - val_rmse: 0.4196\n",
            "Epoch 79/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1911 - rmse: 0.4371 - val_loss: 0.1721 - val_rmse: 0.4149\n",
            "Epoch 80/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1892 - rmse: 0.4349 - val_loss: 0.1688 - val_rmse: 0.4109\n",
            "Epoch 81/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1888 - rmse: 0.4346 - val_loss: 0.1712 - val_rmse: 0.4137\n",
            "Epoch 82/100\n",
            "620/620 [==============================] - 16s 27ms/step - loss: 0.1853 - rmse: 0.4305 - val_loss: 0.1661 - val_rmse: 0.4076\n",
            "Epoch 83/100\n",
            "620/620 [==============================] - 16s 27ms/step - loss: 0.1842 - rmse: 0.4292 - val_loss: 0.1624 - val_rmse: 0.4030\n",
            "Epoch 84/100\n",
            "620/620 [==============================] - 16s 27ms/step - loss: 0.1835 - rmse: 0.4284 - val_loss: 0.1654 - val_rmse: 0.4067\n",
            "Epoch 85/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1840 - rmse: 0.4289 - val_loss: 0.1758 - val_rmse: 0.4192\n",
            "Epoch 86/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1818 - rmse: 0.4264 - val_loss: 0.1666 - val_rmse: 0.4082\n",
            "Epoch 87/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1809 - rmse: 0.4254 - val_loss: 0.1611 - val_rmse: 0.4013\n",
            "Epoch 88/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1796 - rmse: 0.4237 - val_loss: 0.1653 - val_rmse: 0.4066\n",
            "Epoch 89/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1776 - rmse: 0.4214 - val_loss: 0.1654 - val_rmse: 0.4067\n",
            "Epoch 90/100\n",
            "620/620 [==============================] - 16s 27ms/step - loss: 0.1777 - rmse: 0.4215 - val_loss: 0.1556 - val_rmse: 0.3945\n",
            "Epoch 91/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1739 - rmse: 0.4170 - val_loss: 0.1603 - val_rmse: 0.4004\n",
            "Epoch 92/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1732 - rmse: 0.4162 - val_loss: 0.1567 - val_rmse: 0.3959\n",
            "Epoch 93/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1707 - rmse: 0.4131 - val_loss: 0.1714 - val_rmse: 0.4140\n",
            "Epoch 94/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1703 - rmse: 0.4126 - val_loss: 0.1501 - val_rmse: 0.3874\n",
            "Epoch 95/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1710 - rmse: 0.4135 - val_loss: 0.1554 - val_rmse: 0.3943\n",
            "Epoch 96/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1665 - rmse: 0.4080 - val_loss: 0.1464 - val_rmse: 0.3827\n",
            "Epoch 97/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1661 - rmse: 0.4076 - val_loss: 0.1491 - val_rmse: 0.3861\n",
            "Epoch 98/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1663 - rmse: 0.4078 - val_loss: 0.1479 - val_rmse: 0.3846\n",
            "Epoch 99/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1657 - rmse: 0.4071 - val_loss: 0.1470 - val_rmse: 0.3834\n",
            "Epoch 100/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.1627 - rmse: 0.4034 - val_loss: 0.1486 - val_rmse: 0.3855\n",
            "Score for fold 9: loss of 0.14859731495380402; rmse of 38.54832351207733%\n",
            "Epoch 1/100\n",
            "620/620 [==============================] - 17s 26ms/step - loss: 2.1500 - rmse: 1.4663 - val_loss: 0.3357 - val_rmse: 0.5794\n",
            "Epoch 2/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.4790 - rmse: 0.6921 - val_loss: 0.2702 - val_rmse: 0.5198\n",
            "Epoch 3/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.4329 - rmse: 0.6579 - val_loss: 0.2586 - val_rmse: 0.5085\n",
            "Epoch 4/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.4192 - rmse: 0.6475 - val_loss: 0.2989 - val_rmse: 0.5467\n",
            "Epoch 5/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.4010 - rmse: 0.6332 - val_loss: 0.2446 - val_rmse: 0.4945\n",
            "Epoch 6/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.3819 - rmse: 0.6180 - val_loss: 0.3164 - val_rmse: 0.5625\n",
            "Epoch 7/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.3317 - rmse: 0.5760 - val_loss: 0.3471 - val_rmse: 0.5892\n",
            "Epoch 8/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2949 - rmse: 0.5430 - val_loss: 0.2389 - val_rmse: 0.4888\n",
            "Epoch 9/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2736 - rmse: 0.5231 - val_loss: 0.2385 - val_rmse: 0.4883\n",
            "Epoch 10/100\n",
            "620/620 [==============================] - 16s 27ms/step - loss: 0.2736 - rmse: 0.5231 - val_loss: 0.2389 - val_rmse: 0.4888\n",
            "Epoch 11/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2649 - rmse: 0.5147 - val_loss: 0.3349 - val_rmse: 0.5787\n",
            "Epoch 12/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2536 - rmse: 0.5036 - val_loss: 0.2522 - val_rmse: 0.5022\n",
            "Epoch 13/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2509 - rmse: 0.5009 - val_loss: 0.2287 - val_rmse: 0.4783\n",
            "Epoch 14/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2569 - rmse: 0.5068 - val_loss: 0.2250 - val_rmse: 0.4744\n",
            "Epoch 15/100\n",
            "620/620 [==============================] - 16s 27ms/step - loss: 0.2508 - rmse: 0.5008 - val_loss: 0.2743 - val_rmse: 0.5237\n",
            "Epoch 16/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2430 - rmse: 0.4930 - val_loss: 0.2409 - val_rmse: 0.4908\n",
            "Epoch 17/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2463 - rmse: 0.4963 - val_loss: 0.2254 - val_rmse: 0.4748\n",
            "Epoch 18/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2424 - rmse: 0.4924 - val_loss: 0.2358 - val_rmse: 0.4856\n",
            "Epoch 19/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2418 - rmse: 0.4918 - val_loss: 0.2290 - val_rmse: 0.4785\n",
            "Epoch 20/100\n",
            "620/620 [==============================] - 16s 27ms/step - loss: 0.2369 - rmse: 0.4867 - val_loss: 0.2248 - val_rmse: 0.4741\n",
            "Epoch 21/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2446 - rmse: 0.4946 - val_loss: 0.2192 - val_rmse: 0.4682\n",
            "Epoch 22/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2387 - rmse: 0.4885 - val_loss: 0.2397 - val_rmse: 0.4896\n",
            "Epoch 23/100\n",
            "620/620 [==============================] - 16s 27ms/step - loss: 0.2376 - rmse: 0.4874 - val_loss: 0.2374 - val_rmse: 0.4872\n",
            "Epoch 24/100\n",
            "620/620 [==============================] - 16s 27ms/step - loss: 0.2335 - rmse: 0.4832 - val_loss: 0.2164 - val_rmse: 0.4652\n",
            "Epoch 25/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2323 - rmse: 0.4820 - val_loss: 0.2356 - val_rmse: 0.4854\n",
            "Epoch 26/100\n",
            "620/620 [==============================] - 16s 27ms/step - loss: 0.2328 - rmse: 0.4825 - val_loss: 0.2554 - val_rmse: 0.5053\n",
            "Epoch 27/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2330 - rmse: 0.4827 - val_loss: 0.2278 - val_rmse: 0.4773\n",
            "Epoch 28/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2308 - rmse: 0.4804 - val_loss: 0.2162 - val_rmse: 0.4650\n",
            "Epoch 29/100\n",
            "620/620 [==============================] - 16s 26ms/step - loss: 0.2311 - rmse: 0.4808 - val_loss: 0.2235 - val_rmse: 0.4728\n",
            "Epoch 30/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2304 - rmse: 0.4800 - val_loss: 0.2201 - val_rmse: 0.4692\n",
            "Epoch 31/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2253 - rmse: 0.4746 - val_loss: 0.2128 - val_rmse: 0.4613\n",
            "Epoch 32/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2261 - rmse: 0.4755 - val_loss: 0.2187 - val_rmse: 0.4676\n",
            "Epoch 33/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2273 - rmse: 0.4767 - val_loss: 0.2258 - val_rmse: 0.4752\n",
            "Epoch 34/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2248 - rmse: 0.4742 - val_loss: 0.2152 - val_rmse: 0.4638\n",
            "Epoch 35/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2233 - rmse: 0.4726 - val_loss: 0.2180 - val_rmse: 0.4669\n",
            "Epoch 36/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2236 - rmse: 0.4729 - val_loss: 0.2269 - val_rmse: 0.4764\n",
            "Epoch 37/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2245 - rmse: 0.4739 - val_loss: 0.2134 - val_rmse: 0.4620\n",
            "Epoch 38/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2248 - rmse: 0.4741 - val_loss: 0.2121 - val_rmse: 0.4605\n",
            "Epoch 39/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2189 - rmse: 0.4678 - val_loss: 0.2311 - val_rmse: 0.4808\n",
            "Epoch 40/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2216 - rmse: 0.4708 - val_loss: 0.2096 - val_rmse: 0.4578\n",
            "Epoch 41/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2194 - rmse: 0.4684 - val_loss: 0.2148 - val_rmse: 0.4634\n",
            "Epoch 42/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2187 - rmse: 0.4676 - val_loss: 0.2240 - val_rmse: 0.4733\n",
            "Epoch 43/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2198 - rmse: 0.4688 - val_loss: 0.2263 - val_rmse: 0.4758\n",
            "Epoch 44/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2181 - rmse: 0.4670 - val_loss: 0.2103 - val_rmse: 0.4586\n",
            "Epoch 45/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2173 - rmse: 0.4662 - val_loss: 0.2091 - val_rmse: 0.4573\n",
            "Epoch 46/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2172 - rmse: 0.4661 - val_loss: 0.2330 - val_rmse: 0.4827\n",
            "Epoch 47/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2163 - rmse: 0.4651 - val_loss: 0.2128 - val_rmse: 0.4613\n",
            "Epoch 48/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2150 - rmse: 0.4637 - val_loss: 0.2086 - val_rmse: 0.4567\n",
            "Epoch 49/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.2158 - rmse: 0.4646 - val_loss: 0.2153 - val_rmse: 0.4640\n",
            "Epoch 50/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.2156 - rmse: 0.4644 - val_loss: 0.2084 - val_rmse: 0.4565\n",
            "Epoch 51/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.2135 - rmse: 0.4621 - val_loss: 0.2165 - val_rmse: 0.4652\n",
            "Epoch 52/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.2122 - rmse: 0.4606 - val_loss: 0.2233 - val_rmse: 0.4725\n",
            "Epoch 53/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2118 - rmse: 0.4602 - val_loss: 0.2063 - val_rmse: 0.4542\n",
            "Epoch 54/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2095 - rmse: 0.4577 - val_loss: 0.2222 - val_rmse: 0.4714\n",
            "Epoch 55/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2107 - rmse: 0.4590 - val_loss: 0.2106 - val_rmse: 0.4589\n",
            "Epoch 56/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2091 - rmse: 0.4573 - val_loss: 0.2131 - val_rmse: 0.4616\n",
            "Epoch 57/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2093 - rmse: 0.4575 - val_loss: 0.2057 - val_rmse: 0.4535\n",
            "Epoch 58/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2084 - rmse: 0.4565 - val_loss: 0.2063 - val_rmse: 0.4543\n",
            "Epoch 59/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2094 - rmse: 0.4576 - val_loss: 0.2113 - val_rmse: 0.4596\n",
            "Epoch 60/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.2079 - rmse: 0.4559 - val_loss: 0.2046 - val_rmse: 0.4523\n",
            "Epoch 61/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.2066 - rmse: 0.4545 - val_loss: 0.2112 - val_rmse: 0.4596\n",
            "Epoch 62/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2054 - rmse: 0.4532 - val_loss: 0.2186 - val_rmse: 0.4675\n",
            "Epoch 63/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2047 - rmse: 0.4525 - val_loss: 0.2080 - val_rmse: 0.4561\n",
            "Epoch 64/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2043 - rmse: 0.4520 - val_loss: 0.2116 - val_rmse: 0.4600\n",
            "Epoch 65/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2035 - rmse: 0.4511 - val_loss: 0.2004 - val_rmse: 0.4477\n",
            "Epoch 66/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2016 - rmse: 0.4490 - val_loss: 0.2055 - val_rmse: 0.4534\n",
            "Epoch 67/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2020 - rmse: 0.4495 - val_loss: 0.1972 - val_rmse: 0.4440\n",
            "Epoch 68/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2006 - rmse: 0.4478 - val_loss: 0.2011 - val_rmse: 0.4485\n",
            "Epoch 69/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2007 - rmse: 0.4480 - val_loss: 0.2009 - val_rmse: 0.4482\n",
            "Epoch 70/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2003 - rmse: 0.4475 - val_loss: 0.1919 - val_rmse: 0.4381\n",
            "Epoch 71/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.2004 - rmse: 0.4476 - val_loss: 0.2046 - val_rmse: 0.4523\n",
            "Epoch 72/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1966 - rmse: 0.4433 - val_loss: 0.2096 - val_rmse: 0.4578\n",
            "Epoch 73/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1980 - rmse: 0.4450 - val_loss: 0.2006 - val_rmse: 0.4479\n",
            "Epoch 74/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1970 - rmse: 0.4439 - val_loss: 0.1986 - val_rmse: 0.4457\n",
            "Epoch 75/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1958 - rmse: 0.4425 - val_loss: 0.2017 - val_rmse: 0.4492\n",
            "Epoch 76/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1919 - rmse: 0.4381 - val_loss: 0.1876 - val_rmse: 0.4332\n",
            "Epoch 77/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1956 - rmse: 0.4423 - val_loss: 0.2117 - val_rmse: 0.4601\n",
            "Epoch 78/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1920 - rmse: 0.4382 - val_loss: 0.2071 - val_rmse: 0.4551\n",
            "Epoch 79/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1949 - rmse: 0.4415 - val_loss: 0.1890 - val_rmse: 0.4347\n",
            "Epoch 80/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1903 - rmse: 0.4363 - val_loss: 0.1845 - val_rmse: 0.4296\n",
            "Epoch 81/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1890 - rmse: 0.4347 - val_loss: 0.1854 - val_rmse: 0.4306\n",
            "Epoch 82/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1886 - rmse: 0.4343 - val_loss: 0.1863 - val_rmse: 0.4316\n",
            "Epoch 83/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1885 - rmse: 0.4342 - val_loss: 0.2008 - val_rmse: 0.4481\n",
            "Epoch 84/100\n",
            "620/620 [==============================] - 17s 27ms/step - loss: 0.1850 - rmse: 0.4301 - val_loss: 0.2003 - val_rmse: 0.4476\n",
            "Epoch 85/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1860 - rmse: 0.4313 - val_loss: 0.1864 - val_rmse: 0.4318\n",
            "Epoch 86/100\n",
            "620/620 [==============================] - 18s 28ms/step - loss: 0.1838 - rmse: 0.4288 - val_loss: 0.1829 - val_rmse: 0.4276\n",
            "Epoch 87/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1839 - rmse: 0.4288 - val_loss: 0.1945 - val_rmse: 0.4410\n",
            "Epoch 88/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1815 - rmse: 0.4260 - val_loss: 0.1799 - val_rmse: 0.4241\n",
            "Epoch 89/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1824 - rmse: 0.4271 - val_loss: 0.1767 - val_rmse: 0.4204\n",
            "Epoch 90/100\n",
            "620/620 [==============================] - 18s 28ms/step - loss: 0.1786 - rmse: 0.4227 - val_loss: 0.1718 - val_rmse: 0.4145\n",
            "Epoch 91/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1770 - rmse: 0.4207 - val_loss: 0.1790 - val_rmse: 0.4231\n",
            "Epoch 92/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1755 - rmse: 0.4190 - val_loss: 0.1706 - val_rmse: 0.4130\n",
            "Epoch 93/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1757 - rmse: 0.4191 - val_loss: 0.1693 - val_rmse: 0.4114\n",
            "Epoch 94/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1728 - rmse: 0.4157 - val_loss: 0.1993 - val_rmse: 0.4465\n",
            "Epoch 95/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1736 - rmse: 0.4166 - val_loss: 0.1733 - val_rmse: 0.4162\n",
            "Epoch 96/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1710 - rmse: 0.4136 - val_loss: 0.1657 - val_rmse: 0.4070\n",
            "Epoch 97/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1683 - rmse: 0.4102 - val_loss: 0.1776 - val_rmse: 0.4214\n",
            "Epoch 98/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1685 - rmse: 0.4105 - val_loss: 0.1619 - val_rmse: 0.4024\n",
            "Epoch 99/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1640 - rmse: 0.4049 - val_loss: 0.1672 - val_rmse: 0.4089\n",
            "Epoch 100/100\n",
            "620/620 [==============================] - 17s 28ms/step - loss: 0.1651 - rmse: 0.4063 - val_loss: 0.1679 - val_rmse: 0.4098\n",
            "Score for fold 10: loss of 0.16790898144245148; rmse of 40.97669720649719%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=30)\n",
        "initializer2 = tf.keras.initializers.HeNormal()\n",
        "num_folds=10\n",
        "fold_no=1\n",
        "acc_per_fold=[]\n",
        "loss_per_fold=[]\n",
        "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "  model = Sequential([\n",
        "    Dense(1000, activation='elu', input_shape=(756,),kernel_initializer=initializer2),\n",
        "    Dense(800, activation='elu'),\n",
        "    Dense(500, activation='elu'),\n",
        "    Dense(100, activation='elu'),\n",
        "    Dropout(0.1),\n",
        "    Dense(1)])\n",
        "  opt = tf.optimizers.Adamax(learning_rate=0.0004,clipvalue=5)\n",
        "  model.compile(opt,  loss=tf.keras.metrics.mean_squared_error,\n",
        "              metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "  history=model.fit(inputs, targets, epochs=100,validation_data=(inputs[test], targets[test]),callbacks=[callback])\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "                     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmsXkoAEs7ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192302eb-394c-4934-cd48-e1eab10ff150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186/186 [==============================] - 1s 6ms/step - loss: 0.1571 - rmse: 0.3963\n"
          ]
        }
      ],
      "source": [
        "test_loss, rmse = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "#epochs = range(1,100)\n",
        "plt.plot(history.epoch, loss_train, 'g', label='Training loss')\n",
        "plt.plot(history.epoch, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "LHJKS4vnMiKw",
        "outputId": "5985fa43-92b6-4bf8-c267-6999937c7a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg=sum(acc_per_fold)/ len(acc_per_fold)\n"
      ],
      "metadata": {
        "id": "UwjfZEJMgpE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWxgGqt3QW3_",
        "outputId": "f927b181-6305-4d52-909d-3be1b5e1264e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38.83349031209946"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_per_fold"
      ],
      "metadata": {
        "id": "h0vIGWXdjkWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7164521-734b-4720-fca0-cf53ef114eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1510048806667328,\n",
              " 0.14140722155570984,\n",
              " 0.15003830194473267,\n",
              " 0.16590291261672974,\n",
              " 0.1305968165397644,\n",
              " 0.1573638767004013,\n",
              " 0.15097413957118988,\n",
              " 0.14605951309204102,\n",
              " 0.14859731495380402,\n",
              " 0.16790898144245148]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Data')"
      ],
      "metadata": {
        "id": "FYVLShCkiykB",
        "outputId": "958139f9-e484-4524-9b5e-c744182ba334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Data/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py"
      ],
      "metadata": {
        "id": "bmM28xq7gtHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dcafc9b-5783-4efc-bb82-500b8a5345a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njGuzsQDaji3",
        "outputId": "6795602d-ce4a-489d-cf42-3011ccfef562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_45 (Dense)            (None, 1000)              757000    \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 800)               800800    \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 500)               400500    \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 100)               50100     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,008,501\n",
            "Trainable params: 2,008,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "deep_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}